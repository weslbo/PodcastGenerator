{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Generator\n",
    "\n",
    "This notebook support the creation of a podcast .mp3 audio file.\n",
    "\n",
    "When you listen to the generated podcast, you will notice an engaging conversation between the host and a guest, as they talk about the content of your choice. You determine what they talk about, as you can provide a list of web pages to take content from.\n",
    "\n",
    "The podcast generator uses the following technique to create the .mp3:\n",
    "\n",
    "1. Define a list of url's you want to use as the input for the podcast content. The generator will automatically fetch the content of these web pages and translate to markdown language\n",
    "2. Define who are the host and the guest\n",
    "3. For each web page, generate a podcast transcript (where the host and the guest have a conversation). This uses Azure OpenAI gpt3.5 deployed model.\n",
    "4. Transform the podcast transcript to SSML (Speech Synthesis Markup Language)\n",
    "5. Transform the SSML output to audio using Azure Cognitive Service Speech API\n",
    "6. Combine all the .mp3 files into one output\n",
    "\n",
    "Let's first get started by installing the pre-requisites (pip install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the name of the host and the guest. For a full list of voices, check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-text-to-speech?tabs=streaming\n",
    "\n",
    "| LocalName             | ShortName                       | Gender | WordsPerMinute |\n",
    "|-----------------------|---------------------------------|--------|----------------|\n",
    "| Ava                   | en-US-AvaNeural                 | Female |                |\n",
    "| Andrew                | en-US-AndrewNeural              | Male   |                |\n",
    "| Emma                  | en-US-EmmaNeural                | Female |                |\n",
    "| Brian                 | en-US-BrianNeural               | Male   |                |\n",
    "| Jenny *               | en-US-JennyNeural               | Female | 152            |\n",
    "| Guy *                 | en-US-GuyNeural                 | Male   | 215            |\n",
    "| Aria *                | en-US-AriaNeural                | Female | 150            |\n",
    "| Davis *               | en-US-DavisNeural               | Male   | 154            |\n",
    "| Jane *                | en-US-JaneNeural                | Female | 154            |\n",
    "| Jason *               | en-US-JasonNeural               | Male   | 156            |\n",
    "| Sara *                | en-US-SaraNeural                | Female | 157            |\n",
    "| Tony *                | en-US-TonyNeural                | Male   | 156            |\n",
    "| Nancy *               | en-US-NancyNeural               | Female | 149            |\n",
    "| Amber                 | en-US-AmberNeural               | Female | 152            |\n",
    "| Ana                   | en-US-AnaNeural                 | Female | 135            |\n",
    "| Ashley                | en-US-AshleyNeural              | Female | 149            |\n",
    "| Brandon               | en-US-BrandonNeural             | Male   | 156            |\n",
    "| Christopher           | en-US-ChristopherNeural         | Male   | 149            |\n",
    "| Cora                  | en-US-CoraNeural                | Female | 146            |\n",
    "| Elizabeth             | en-US-ElizabethNeural           | Female | 152            |\n",
    "| Eric                  | en-US-EricNeural                | Male   | 147            |\n",
    "| Jacob                 | en-US-JacobNeural               | Male   | 154            |\n",
    "| Jenny Multilingual    | en-US-JennyMultilingualNeural   | Female | 190            |\n",
    "| Jenny Multilingual V2 | en-US-JennyMultilingualV2Neural | Female | 190            |\n",
    "| Michelle              | en-US-MichelleNeural            | Female | 154            |\n",
    "| Monica                | en-US-MonicaNeural              | Female | 145            |\n",
    "| Roger                 | en-US-RogerNeural               | Male   |                |\n",
    "| Ryan Multilingual     | en-US-RyanMultilingualNeural    | Male   | 190            |\n",
    "| Steffan               | en-US-SteffanNeural             | Male   | 154            |\n",
    "\n",
    "** Have styles in preview (for example, assistant, newscast, angry, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"Brian\"\n",
    "guest = \"Andrew\"\n",
    "list_of_urls = [\n",
    "    \"https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/1-introduction\", \n",
    "    \"https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/2-understand-data-warehouse\", \n",
    "    \"https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/3-understand-data-warehouse-fabric\",\n",
    "    \"https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/4-query-transform-data\",\n",
    "    \"https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/5-model-data\",\n",
    "    \"https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/6-security-monitor\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import requests\n",
    "import markdownify\n",
    "import re\n",
    "import json\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from openai import AzureOpenAI\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve markdown text for a URL\n",
    "\n",
    "The following function will download the page content from the URL parameter. \n",
    "\n",
    "- It will then find the div with id `unit-inner-section`. \n",
    "- Next, it removes some metadata from the HTML. \n",
    "- Finally, the returning text will be transformed to markdown content as the return value for this function. Markdown is a bit easier to work with when using it as input for gpt model (as it will preserve headers, ...)\n",
    "- The function will also store the markdown content in the output folder (mainly for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markdown(url, index):\n",
    "    print(\"- Retrieving markdown from \" + url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # might need to adapt this when working with other web pages (not Microsoft Learn)\n",
    "    div = soup.find(id=\"unit-inner-section\")\n",
    "\n",
    "    for ul in div.find_all(\"ul\", class_=\"metadata\"):\n",
    "        ul.decompose()\n",
    "    for d in div.find_all(\"div\", class_=\"xp-tag\"):\n",
    "        d.decompose()\n",
    "    for next in div.find_all(\"div\", class_=\"next-section\"):\n",
    "        next.decompose()\n",
    "    for header in div.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "        header.string = \"\\n# \" + header.get_text() + \"\\n\"\n",
    "    for u in div.find_all([\"li\"]):\n",
    "        u.string = \"- \" + u.get_text()\n",
    "\n",
    "    markdown = markdownify.markdownify(str(div), heading_style=\"ATX\", bullets=\"-\")\n",
    "    markdown = re.sub('\\n{3,}', '\\n\\n', markdown)\n",
    "\n",
    "    with open(f\"output/{index}-markdown.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(markdown)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Azure OpenAI chat response\n",
    "\n",
    "This function will call the Azure OpenAI GPT model. Follow these steps:\n",
    "\n",
    "1. Deploy an Azure OpenAI Service resource (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)\n",
    "2. Deploy a model \"gpt-35-turbo-16k\". If possible, you can also deploy \"gpt-4-32k\" if quota is available. The more tokens you have, the less issues you will experience when calling the chat service. (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model)\n",
    "3. Retrieve the OPENAI_API_KEY and store it in the .env file\n",
    "\n",
    "The following code makes use op some predefined prompts. The idea is that every webpage (markdown) will be attached as content when asking the gpt model to generate a podcast transcript. Since we want the transcript opening and closing section to be different, we have multiple prompts.\n",
    "\n",
    "Notice that the characters of the host and guest are defined in another template.\n",
    "\n",
    "For troubleshooting purposes, the output of the chat completion is also stored as a file in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(action, content, index):\n",
    "    print(f\"- Retrieving chat response ({action})\")\n",
    "    client = AzureOpenAI(azure_endpoint=\"https://wedebolsaiopenai2.openai.azure.com/\", api_version=\"2023-07-01-preview\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    with open(\"prompts/prompt_characters.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt_characters = text_file.read()\n",
    "\n",
    "    with open(f\"prompts/prompt_{action}.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt = text_file.read()\n",
    "\n",
    "    prompt = prompt.replace(\"{characters}\", prompt_characters)\n",
    "    prompt = prompt.replace(\"{host}\", host)\n",
    "    prompt = prompt.replace(\"{guest}\", guest)\n",
    "    prompt = prompt.replace(\"{content}\", content)\n",
    "\n",
    "    message_text = [\n",
    "        {\"role\":\"system\",\"content\":prompt},\n",
    "        {\"role\":\"user\",\"content\":\"Create the podcast\"}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-16k\",\n",
    "        messages = message_text,\n",
    "        temperature=0.2,\n",
    "        max_tokens=13000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "\n",
    "    with open(f\"output/{index}-chatresponse-{action}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MP3 audio\n",
    "\n",
    "The following function takes the SSML transcript and uses the Azure Speech Service to transform the text into speech.\n",
    "\n",
    "1. You will need to deploy an Azure Speech Service. Check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-text-to-speech for more information.\n",
    "2. Fetch the SPEECH_API_KEY and store in the .env file.\n",
    "\n",
    "As a result, an .mp3 file will be created in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(ssml, index):\n",
    "    print(\"- Creating audio\")\n",
    "    \n",
    "    service_region = \"eastus\"\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3)  \n",
    "\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=f\"output/{index}-podcast.mp3\")\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)  \n",
    "\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append multiple mp3 files\n",
    "\n",
    "Since we have multiple .mp3 files, we want to merge/append them together sequentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_mp3_files(input_files, output_file):\n",
    "    print(\"- Combining audio files \" + str(input_files))\n",
    "    # Initialize an empty AudioSegment\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through input files and append them to the combined_audio\n",
    "    for input_file in input_files:\n",
    "        audio_segment = AudioSegment.from_file(input_file, format=\"mp3\")\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Export the combined audio to the output file\n",
    "    combined_audio.export(output_file, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete all files previouslly generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in the output folder have been deleted.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = \"output\"\n",
    "\n",
    "# Get all file names in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Iterate over the file names and delete each file\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    os.remove(file_path)\n",
    "\n",
    "print(\"All files in the output folder have been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 (start): https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/1-introduction\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/1-introduction\n",
      "- Retrieving chat response (start)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "Part 2 (between): https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/2-understand-data-warehouse\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/2-understand-data-warehouse\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "Part 3 (between): https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/3-understand-data-warehouse-fabric\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/3-understand-data-warehouse-fabric\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "Part 4 (between): https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/4-query-transform-data\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/4-query-transform-data\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "Part 5 (between): https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/5-model-data\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/5-model-data\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "Part 6 (finish): https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/6-security-monitor\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/6-security-monitor\n",
      "- Retrieving chat response (finish)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for index, url in enumerate(list_of_urls):\n",
    "    if index == 0:\n",
    "        action = \"start\"\n",
    "    elif index == len(list_of_urls) - 1:\n",
    "        action = \"finish\"\n",
    "    else:\n",
    "        action = \"between\"\n",
    "    \n",
    "    print(f\"Part {index+1} ({action}): {url}\")\n",
    "\n",
    "    markdown = get_markdown(url, index+1)\n",
    "    transcript = get_chat_response(action, markdown, index+1)\n",
    "    ssml = get_chat_response(\"ssml\", transcript, index+1)\n",
    "    audio = get_audio(ssml, index+1)\n",
    "\n",
    "    #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the combined podcast .mp3 file\n",
    "\n",
    "This code will first get a list of all the generated .mp3 files, and combine them with a couple of short audio tunes to indicate start, break and finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Combining audio files ['media\\\\start.mp3', 'output\\\\1-podcast.mp3', 'media\\\\break.mp3', 'output\\\\2-podcast.mp3', 'media\\\\break.mp3', 'output\\\\3-podcast.mp3', 'media\\\\break.mp3', 'output\\\\4-podcast.mp3', 'media\\\\break.mp3', 'output\\\\5-podcast.mp3', 'media\\\\break.mp3', 'output\\\\6-podcast.mp3', 'media/finish.mp3']\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "output_file = \"combined_podcast.mp3\"\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "folder_path = \"output\"\n",
    "input_files = fnmatch.filter(os.listdir(folder_path), '*.mp3')\n",
    "final_files = []\n",
    "\n",
    "for i in range(len(input_files)):\n",
    "    input_files[i] = os.path.join(folder_path, input_files[i])\n",
    "\n",
    "for i in range(len(input_files)):\n",
    "    if i == 0:\n",
    "        final_files.append(\"media\\\\start.mp3\")\n",
    "        final_files.append(input_files[i])\n",
    "    elif i == len(input_files) - 1:\n",
    "        final_files.append(\"media\\\\break.mp3\")\n",
    "        final_files.append(input_files[i])\n",
    "        final_files.append(\"media/finish.mp3\")\n",
    "    else:\n",
    "        final_files.append(\"media\\\\break.mp3\")\n",
    "        final_files.append(input_files[i])\n",
    "\n",
    "append_mp3_files(final_files, output_file)\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
