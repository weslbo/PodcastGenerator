{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Generator\n",
    "\n",
    "This notebook support the creation of a podcast .mp3 audio file.\n",
    "\n",
    "When you listen to the generated podcast, you will notice an engaging conversation between the host and a guest, as they talk about the content of your choice. You determine what they talk about, as you can provide a list of web pages to take content from.\n",
    "\n",
    "The podcast generator uses the following technique to create the .mp3:\n",
    "\n",
    "1. Define a list of url's you want to use as the input for the podcast content. The generator will automatically fetch the content of these web pages and translate to markdown language\n",
    "2. Define who are the host and the guest\n",
    "3. For each web page, generate a podcast transcript (where the host and the guest have a conversation). This uses Azure OpenAI gpt3.5 deployed model.\n",
    "4. Transform the podcast transcript to SSML (Speech Synthesis Markup Language)\n",
    "5. Transform the SSML output to audio using Azure Cognitive Service Speech API\n",
    "6. Combine all the .mp3 files into one output\n",
    "\n",
    "Let's first get started by installing the pre-requisites (pip install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 1)) (0.0.2)\n",
      "Requirement already satisfied: markdownify in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 2)) (0.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: azure.cognitiveservices.speech in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 4)) (1.34.1)\n",
      "Requirement already satisfied: AzureOpenAI in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 5)) (0.0.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: openai in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 8)) (0.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bs4->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdownify->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from AzureOpenAI->-r requirements.txt (line 5)) (3.9.3)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from AzureOpenAI->-r requirements.txt (line 5)) (4.21.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.16.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (1.9.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema->AzureOpenAI->-r requirements.txt (line 5)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema->AzureOpenAI->-r requirements.txt (line 5)) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema->AzureOpenAI->-r requirements.txt (line 5)) (0.17.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\wedebols\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the name of the host and the guest. For a full list of voices, check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-text-to-speech?tabs=streaming\n",
    "\n",
    "| LocalName             | ShortName                       | Gender | WordsPerMinute |\n",
    "|-----------------------|---------------------------------|--------|----------------|\n",
    "| Ava                   | en-US-AvaNeural                 | Female |                |\n",
    "| Andrew                | en-US-AndrewNeural              | Male   |                |\n",
    "| Emma                  | en-US-EmmaNeural                | Female |                |\n",
    "| Brian                 | en-US-BrianNeural               | Male   |                |\n",
    "| Jenny *               | en-US-JennyNeural               | Female | 152            |\n",
    "| Guy *                 | en-US-GuyNeural                 | Male   | 215            |\n",
    "| Aria *                | en-US-AriaNeural                | Female | 150            |\n",
    "| Davis *               | en-US-DavisNeural               | Male   | 154            |\n",
    "| Jane *                | en-US-JaneNeural                | Female | 154            |\n",
    "| Jason *               | en-US-JasonNeural               | Male   | 156            |\n",
    "| Sara *                | en-US-SaraNeural                | Female | 157            |\n",
    "| Tony *                | en-US-TonyNeural                | Male   | 156            |\n",
    "| Nancy *               | en-US-NancyNeural               | Female | 149            |\n",
    "| Amber                 | en-US-AmberNeural               | Female | 152            |\n",
    "| Ana                   | en-US-AnaNeural                 | Female | 135            |\n",
    "| Ashley                | en-US-AshleyNeural              | Female | 149            |\n",
    "| Brandon               | en-US-BrandonNeural             | Male   | 156            |\n",
    "| Christopher           | en-US-ChristopherNeural         | Male   | 149            |\n",
    "| Cora                  | en-US-CoraNeural                | Female | 146            |\n",
    "| Elizabeth             | en-US-ElizabethNeural           | Female | 152            |\n",
    "| Eric                  | en-US-EricNeural                | Male   | 147            |\n",
    "| Jacob                 | en-US-JacobNeural               | Male   | 154            |\n",
    "| Jenny Multilingual    | en-US-JennyMultilingualNeural   | Female | 190            |\n",
    "| Jenny Multilingual V2 | en-US-JennyMultilingualV2Neural | Female | 190            |\n",
    "| Michelle              | en-US-MichelleNeural            | Female | 154            |\n",
    "| Monica                | en-US-MonicaNeural              | Female | 145            |\n",
    "| Roger                 | en-US-RogerNeural               | Male   |                |\n",
    "| Ryan Multilingual     | en-US-RyanMultilingualNeural    | Male   | 190            |\n",
    "| Steffan               | en-US-SteffanNeural             | Male   | 154            |\n",
    "\n",
    "** Have styles in preview (for example, assistant, newscast, angry, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"Brian\"\n",
    "guest = \"Andrew\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import requests\n",
    "import markdownify\n",
    "import re\n",
    "import json\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from openai import AzureOpenAI\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve markdown text for a URL\n",
    "\n",
    "The following function will download the page content from the URL parameter. \n",
    "\n",
    "- It will then find the div with id `unit-inner-section`. \n",
    "- Next, it removes some metadata from the HTML. \n",
    "- Finally, the returning text will be transformed to markdown content as the return value for this function. Markdown is a bit easier to work with when using it as input for gpt model (as it will preserve headers, ...)\n",
    "- The function will also store the markdown content in the output folder (mainly for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markdown(url, savelocation):\n",
    "    print(\"- Retrieving markdown from \" + url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # might need to adapt this when working with other web pages (not Microsoft Learn)\n",
    "    div = soup.find(id=\"unit-inner-section\")\n",
    "\n",
    "    for ul in div.find_all(\"ul\", class_=\"metadata\"):\n",
    "        ul.decompose()\n",
    "    for d in div.find_all(\"div\", class_=\"xp-tag\"):\n",
    "        d.decompose()\n",
    "    for next in div.find_all(\"div\", class_=\"next-section\"):\n",
    "        next.decompose()\n",
    "    for header in div.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "        header.string = \"\\n# \" + header.get_text() + \"\\n\"\n",
    "    for u in div.find_all([\"li\"]):\n",
    "        u.string = \"- \" + u.get_text()\n",
    "    for code in div.find_all(\"code\"):\n",
    "        code.decompose()\n",
    "\n",
    "    markdown = markdownify.markdownify(str(div), heading_style=\"ATX\", bullets=\"-\")\n",
    "    markdown = re.sub('\\n{3,}', '\\n\\n', markdown)\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(markdown)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Azure OpenAI chat response\n",
    "\n",
    "This function will call the Azure OpenAI GPT model. Follow these steps:\n",
    "\n",
    "1. Deploy an Azure OpenAI Service resource (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)\n",
    "2. Deploy a model \"gpt-35-turbo-16k\". If possible, you can also deploy \"gpt-4-32k\" if quota is available. The more tokens you have, the less issues you will experience when calling the chat service. (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model)\n",
    "3. Retrieve the OPENAI_API_KEY and store it in the .env file\n",
    "\n",
    "The following code makes use op some predefined prompts. The idea is that every webpage (markdown) will be attached as content when asking the gpt model to generate a podcast transcript. Since we want the transcript opening and closing section to be different, we have multiple prompts.\n",
    "\n",
    "Notice that the characters of the host and guest are defined in another template.\n",
    "\n",
    "For troubleshooting purposes, the output of the chat completion is also stored as a file in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(action, content, savelocation):\n",
    "    print(f\"- Retrieving chat response ({action})\")\n",
    "    client = AzureOpenAI(azure_endpoint=\"https://wedebolsaiopenai2.openai.azure.com/\", api_version=\"2023-07-01-preview\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    with open(\"prompts/prompt_characters.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt_characters = text_file.read()\n",
    "\n",
    "    with open(f\"prompts/prompt_{action}.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt = text_file.read()\n",
    "\n",
    "    prompt = prompt.replace(\"{characters}\", prompt_characters)\n",
    "    prompt = prompt.replace(\"{host}\", host)\n",
    "    prompt = prompt.replace(\"{guest}\", guest)\n",
    "    prompt = prompt.replace(\"{content}\", content)\n",
    "\n",
    "    message_text = [\n",
    "        {\"role\":\"system\",\"content\":prompt},\n",
    "        {\"role\":\"user\",\"content\":\"Create the podcast\"}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-16k\",\n",
    "        messages = message_text,\n",
    "        temperature=0.2,\n",
    "        max_tokens=13000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MP3 audio\n",
    "\n",
    "The following function takes the SSML transcript and uses the Azure Speech Service to transform the text into speech.\n",
    "\n",
    "1. You will need to deploy an Azure Speech Service. Check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-text-to-speech for more information.\n",
    "2. Fetch the SPEECH_API_KEY and store in the .env file.\n",
    "\n",
    "As a result, an .mp3 file will be created in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(ssml, savelocation):\n",
    "    print(\"- Creating audio\")\n",
    "    \n",
    "    service_region = \"eastus\"\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3)  \n",
    "\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=savelocation)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)  \n",
    "\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append multiple mp3 files\n",
    "\n",
    "Since we have multiple .mp3 files, we want to merge/append them together sequentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_mp3_files(input_files, output_file):\n",
    "    print(\"- Combining audio files \" + str(input_files))\n",
    "    # Initialize an empty AudioSegment\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through input files and append them to the combined_audio\n",
    "    for input_file in input_files:\n",
    "        audio_segment = AudioSegment.from_file(input_file, format=\"mp3\")\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Export the combined audio to the output file\n",
    "    combined_audio.export(output_file, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the combined podcast .mp3 file\n",
    "\n",
    "This code will first get a list of all the generated .mp3 files, and combine them with a couple of short audio tunes to indicate start, break and finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineAudio(templocation, savelocation, modulename):\n",
    "    input_files = fnmatch.filter(os.listdir(templocation), '*.mp3')\n",
    "    final_files = []\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        input_files[i] = os.path.join(templocation, input_files[i])\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        if i == 0:\n",
    "            final_files.append(\"media\\\\start.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "        elif i == len(input_files) - 1:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "            final_files.append(\"media/finish.mp3\")\n",
    "        else:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "\n",
    "    append_mp3_files(final_files, f\"{savelocation}\\\\{modulename}.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory not found\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/1-introduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving chat response (start)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/2-dataflows-gen-2\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/3-explore-dataflows-gen-2\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/4-dataflow-pipeline\n",
      "- Retrieving chat response (finish)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest Data with Dataflows Gen2 in Microsoft Fabric\\\\1-introduction.mp3', 'media\\\\break.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest Data with Dataflows Gen2 in Microsoft Fabric\\\\2-dataflows-gen-2.mp3', 'media\\\\break.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest Data with Dataflows Gen2 in Microsoft Fabric\\\\3-explore-dataflows-gen-2.mp3', 'media\\\\break.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest Data with Dataflows Gen2 in Microsoft Fabric\\\\4-dataflow-pipeline.mp3', 'media/finish.mp3']\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/1-introduction\n",
      "- Retrieving chat response (start)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/2-connect-authenticate\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/3-write-optimize\n",
      "- Retrieving chat response (between)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/4-considerations\n",
      "- Retrieving chat response (finish)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest data with Spark and Microsoft Fabric notebooks\\\\1-introduction.mp3', 'media\\\\break.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest data with Spark and Microsoft Fabric notebooks\\\\2-connect-authenticate.mp3', 'media\\\\break.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest data with Spark and Microsoft Fabric notebooks\\\\3-write-optimize.mp3', 'media\\\\break.mp3', 'temp/Ingest data with Microsoft Fabric/Ingest data with Spark and Microsoft Fabric notebooks\\\\4-considerations.mp3', 'media/finish.mp3']\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/1-introduction\n",
      "- Retrieving chat response (start)\n",
      "- Retrieving chat response (ssml)\n",
      "- Creating audio\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m get_chat_response(action, markdown, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.transcript.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     ssml \u001b[38;5;241m=\u001b[39m get_chat_response(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssml\u001b[39m\u001b[38;5;124m\"\u001b[39m, transcript, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ssml.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mget_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemp/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_module\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43munit_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m combineAudio(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, module[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#break\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mget_audio\u001b[1;34m(ssml, savelocation)\u001b[0m\n\u001b[0;32m      9\u001b[0m file_config \u001b[38;5;241m=\u001b[39m speechsdk\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mAudioOutputConfig(filename\u001b[38;5;241m=\u001b[39msavelocation)\n\u001b[0;32m     10\u001b[0m speech_synthesizer \u001b[38;5;241m=\u001b[39m speechsdk\u001b[38;5;241m.\u001b[39mSpeechSynthesizer(speech_config\u001b[38;5;241m=\u001b[39mspeech_config, audio_config\u001b[38;5;241m=\u001b[39mfile_config)  \n\u001b[1;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mspeech_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeak_ssml_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssml\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\azure\\cognitiveservices\\speech\\speech.py:575\u001b[0m, in \u001b[0;36mResultFuture.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03mWaits until the result is available, and returns it.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__resolved:\n\u001b[1;32m--> 575\u001b[0m     result_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped_type(result_handle)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\azure\\cognitiveservices\\speech\\speech.py:2221\u001b[0m, in \u001b[0;36mSpeechSynthesizer.speak_ssml_async.<locals>.resolve_future\u001b[1;34m(handle)\u001b[0m\n\u001b[0;32m   2219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve_future\u001b[39m(handle: _spx_handle):\n\u001b[0;32m   2220\u001b[0m     result_handle \u001b[38;5;241m=\u001b[39m _spx_handle(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 2221\u001b[0m     \u001b[43m_call_hr_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_sdk_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesizer_speak_async_wait_for\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_uint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2222\u001b[0m     _sdk_lib\u001b[38;5;241m.\u001b[39msynthesizer_async_handle_release(handle)\n\u001b[0;32m   2223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_handle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\azure\\cognitiveservices\\speech\\interop.py:61\u001b[0m, in \u001b[0;36m_call_hr_fn\u001b[1;34m(fn, *args)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_hr_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, fn):\n\u001b[0;32m     60\u001b[0m     fn\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m _spx_hr\n\u001b[1;32m---> 61\u001b[0m     hr \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m fn()\n\u001b[0;32m     62\u001b[0m     _raise_if_failed(hr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(\"temp\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Directory not found\")\n",
    "finally:\n",
    "    os.mkdir(\"temp\")\n",
    "\n",
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "    os.mkdir(f\"temp/{lp['learning_path']}\")\n",
    "    for module in lp[\"learning_modules\"]:\n",
    "        os.mkdir(f\"temp/{lp['learning_path']}/{module['learning_module']}\")\n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            if index == 0:\n",
    "                action = \"start\"\n",
    "            elif index == len(module[\"learning_units\"]) - 1:\n",
    "                action = \"finish\"\n",
    "            else:\n",
    "                action = \"between\"\n",
    "            \n",
    "            markdown = get_markdown(url, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.md\")\n",
    "            transcript = get_chat_response(action, markdown, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.transcript.txt\")\n",
    "            ssml = get_chat_response(\"ssml\", transcript, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.ssml.txt\")\n",
    "            audio = get_audio(ssml, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.mp3\")\n",
    "\n",
    "        combineAudio(f\"temp/{lp['learning_path']}/{module['learning_module']}\", \"output\", module['learning_module'])\n",
    "        #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
