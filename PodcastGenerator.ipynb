{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Generator\n",
    "\n",
    "This notebook support the creation of a podcast .mp3 audio file.\n",
    "\n",
    "When you listen to the generated podcast, you will notice an engaging conversation between the host and a guest, as they talk about the content of your choice. You determine what they talk about, as you can provide a list of web pages to take content from.\n",
    "\n",
    "The podcast generator uses the following technique to create the .mp3:\n",
    "\n",
    "1. Define a list of url's you want to use as the input for the podcast content. The generator will automatically fetch the content of these web pages and translate to markdown language\n",
    "2. Define who are the host and the guest\n",
    "3. For each web page, generate a podcast transcript (where the host and the guest have a conversation). This uses Azure OpenAI gpt3.5 deployed model.\n",
    "4. Transform the podcast transcript to SSML (Speech Synthesis Markup Language)\n",
    "5. Transform the SSML output to audio using Azure Cognitive Service Speech API\n",
    "6. Combine all the .mp3 files into one output\n",
    "\n",
    "Let's first get started by installing the pre-requisites (pip install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 1)) (0.0.2)\n",
      "Requirement already satisfied: markdownify in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 2)) (0.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: azure.cognitiveservices.speech in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 4)) (1.34.1)\n",
      "Requirement already satisfied: AzureOpenAI in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 5)) (0.0.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: openai in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 8)) (0.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bs4->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdownify->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->-r requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from AzureOpenAI->-r requirements.txt (line 5)) (3.9.3)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from AzureOpenAI->-r requirements.txt (line 5)) (4.21.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.16.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->AzureOpenAI->-r requirements.txt (line 5)) (1.9.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema->AzureOpenAI->-r requirements.txt (line 5)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema->AzureOpenAI->-r requirements.txt (line 5)) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\wedebols\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema->AzureOpenAI->-r requirements.txt (line 5)) (0.17.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\wedebols\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the name of the host and the guest. For a full list of voices, check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-text-to-speech?tabs=streaming\n",
    "\n",
    "| LocalName             | ShortName                       | Gender | WordsPerMinute |\n",
    "|-----------------------|---------------------------------|--------|----------------|\n",
    "| Ava                   | en-US-AvaNeural                 | Female |                |\n",
    "| Andrew                | en-US-AndrewNeural              | Male   |                |\n",
    "| Emma                  | en-US-EmmaNeural                | Female |                |\n",
    "| Brian                 | en-US-BrianNeural               | Male   |                |\n",
    "| Jenny *               | en-US-JennyNeural               | Female | 152            |\n",
    "| Guy *                 | en-US-GuyNeural                 | Male   | 215            |\n",
    "| Aria *                | en-US-AriaNeural                | Female | 150            |\n",
    "| Davis *               | en-US-DavisNeural               | Male   | 154            |\n",
    "| Jane *                | en-US-JaneNeural                | Female | 154            |\n",
    "| Jason *               | en-US-JasonNeural               | Male   | 156            |\n",
    "| Sara *                | en-US-SaraNeural                | Female | 157            |\n",
    "| Tony *                | en-US-TonyNeural                | Male   | 156            |\n",
    "| Nancy *               | en-US-NancyNeural               | Female | 149            |\n",
    "| Amber                 | en-US-AmberNeural               | Female | 152            |\n",
    "| Ana                   | en-US-AnaNeural                 | Female | 135            |\n",
    "| Ashley                | en-US-AshleyNeural              | Female | 149            |\n",
    "| Brandon               | en-US-BrandonNeural             | Male   | 156            |\n",
    "| Christopher           | en-US-ChristopherNeural         | Male   | 149            |\n",
    "| Cora                  | en-US-CoraNeural                | Female | 146            |\n",
    "| Elizabeth             | en-US-ElizabethNeural           | Female | 152            |\n",
    "| Eric                  | en-US-EricNeural                | Male   | 147            |\n",
    "| Jacob                 | en-US-JacobNeural               | Male   | 154            |\n",
    "| Jenny Multilingual    | en-US-JennyMultilingualNeural   | Female | 190            |\n",
    "| Jenny Multilingual V2 | en-US-JennyMultilingualV2Neural | Female | 190            |\n",
    "| Michelle              | en-US-MichelleNeural            | Female | 154            |\n",
    "| Monica                | en-US-MonicaNeural              | Female | 145            |\n",
    "| Roger                 | en-US-RogerNeural               | Male   |                |\n",
    "| Ryan Multilingual     | en-US-RyanMultilingualNeural    | Male   | 190            |\n",
    "| Steffan               | en-US-SteffanNeural             | Male   | 154            |\n",
    "\n",
    "** Have styles in preview (for example, assistant, newscast, angry, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"Brian\"\n",
    "guest = \"Emma\"\n",
    "podcast_title = \"AI3003, Develop natural language processing solutions with Azure AI Services\"\n",
    "code = \"AI-3003\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import requests\n",
    "import markdownify\n",
    "import re\n",
    "import json\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from openai import AzureOpenAI\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve markdown text for a URL\n",
    "\n",
    "The following function will download the page content from the URL parameter. \n",
    "\n",
    "- It will then find the div with id `unit-inner-section`. \n",
    "- Next, it removes some metadata from the HTML. \n",
    "- Finally, the returning text will be transformed to markdown content as the return value for this function. Markdown is a bit easier to work with when using it as input for gpt model (as it will preserve headers, ...)\n",
    "- The function will also store the markdown content in the output folder (mainly for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markdown(url, savelocation):\n",
    "    print(\"- Retrieving markdown from \" + url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # might need to adapt this when working with other web pages (not Microsoft Learn)\n",
    "    div = soup.find(id=\"unit-inner-section\")\n",
    "\n",
    "    for ul in div.find_all(\"ul\", class_=\"metadata\"):\n",
    "        ul.decompose()\n",
    "    for d in div.find_all(\"div\", class_=\"xp-tag\"):\n",
    "        d.decompose()\n",
    "    for next in div.find_all(\"div\", class_=\"next-section\"):\n",
    "        next.decompose()\n",
    "    for header in div.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "        header.string = \"\\n# \" + header.get_text() + \"\\n\"\n",
    "    for u in div.find_all([\"li\"]):\n",
    "        u.string = \"- \" + u.get_text()\n",
    "    for code in div.find_all(\"code\"):\n",
    "        code.decompose()\n",
    "\n",
    "    markdown = markdownify.markdownify(str(div), heading_style=\"ATX\", bullets=\"-\")\n",
    "    markdown = re.sub('\\n{3,}', '\\n\\n', markdown)\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(markdown)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Azure OpenAI chat response\n",
    "\n",
    "This function will call the Azure OpenAI GPT model. Follow these steps:\n",
    "\n",
    "1. Deploy an Azure OpenAI Service resource (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)\n",
    "2. Deploy a model \"gpt-35-turbo-16k\". If possible, you can also deploy \"gpt-4-32k\" if quota is available. The more tokens you have, the less issues you will experience when calling the chat service. (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model)\n",
    "3. Retrieve the OPENAI_API_KEY and store it in the .env file\n",
    "\n",
    "The following code makes use op some predefined prompts. The idea is that every webpage (markdown) will be attached as content when asking the gpt model to generate a podcast transcript. Since we want the transcript opening and closing section to be different, we have multiple prompts.\n",
    "\n",
    "Notice that the characters of the host and guest are defined in another template.\n",
    "\n",
    "For troubleshooting purposes, the output of the chat completion is also stored as a file in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(action, content, savelocation, maxtokens=13000):\n",
    "    print(f\"- Retrieving chat response ({action}, maxtokens={maxtokens})\")\n",
    "    client = AzureOpenAI(azure_endpoint=\"https://wedebolsaiopenai2.openai.azure.com/\", api_version=\"2023-07-01-preview\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    with open(\"prompts/prompt_characters.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt_characters = text_file.read()\n",
    "\n",
    "    with open(f\"prompts/prompt_{action}.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt = text_file.read()\n",
    "\n",
    "    prompt = prompt.replace(\"{characters}\", prompt_characters)\n",
    "    prompt = prompt.replace(\"{host}\", host)\n",
    "    prompt = prompt.replace(\"{guest}\", guest)\n",
    "    prompt = prompt.replace(\"{content}\", content)\n",
    "    prompt = prompt.replace(\"{podcast_title}\", podcast_title)\n",
    "\n",
    "    message_text = [\n",
    "        {\"role\":\"system\",\"content\":prompt},\n",
    "        {\"role\":\"user\",\"content\":\"Generate the conversation\"}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-16k\",\n",
    "        messages = message_text,\n",
    "        temperature=0.1,\n",
    "        #max_tokens=maxtokens,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    print(f\"- Actual total usage token={completion.usage.total_tokens}\")\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MP3 audio\n",
    "\n",
    "The following function takes the SSML transcript and uses the Azure Speech Service to transform the text into speech.\n",
    "\n",
    "1. You will need to deploy an Azure Speech Service. Check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-text-to-speech for more information.\n",
    "2. Fetch the SPEECH_API_KEY and store in the .env file.\n",
    "\n",
    "As a result, an .mp3 file will be created in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(ssml, savelocation):\n",
    "    print(f\"- Creating audio {savelocation}\")\n",
    "    \n",
    "    service_region = \"eastus\"\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3)  \n",
    "\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=savelocation)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)  \n",
    "\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append multiple mp3 files\n",
    "\n",
    "Since we have multiple .mp3 files, we want to merge/append them together sequentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_mp3_files(input_files, output_file):\n",
    "    print(\"- Combining audio files \" + str(input_files))\n",
    "    # Initialize an empty AudioSegment\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through input files and append them to the combined_audio\n",
    "    for input_file in input_files:\n",
    "        audio_segment = AudioSegment.from_file(input_file, format=\"mp3\")\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Export the combined audio to the output file\n",
    "    combined_audio.export(output_file, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the combined podcast .mp3 file\n",
    "\n",
    "This code will first get a list of all the generated .mp3 files, and combine them with a couple of short audio tunes to indicate start, break and finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineAudio(templocation, savelocation, modulename):\n",
    "    input_files = fnmatch.filter(os.listdir(templocation), '*.mp3')\n",
    "    final_files = []\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        input_files[i] = os.path.join(templocation, input_files[i])\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        if i == 0:\n",
    "            final_files.append(\"media\\\\start.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "        elif i == len(input_files) - 1:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "            final_files.append(\"media/finish.mp3\")\n",
    "        elif i == 1:\n",
    "            final_files.append(input_files[i]) # skip the first break (as the introduction is only a few minutes long)\n",
    "        else:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "\n",
    "    append_mp3_files(final_files, f\"{savelocation}\\\\{modulename}.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text): \n",
    "    nrOfWords = len(text.split())\n",
    "    return nrOfWords\n",
    "\n",
    "def calculate_approx_tokens(text):\n",
    "    nrOfTokens = round(calculate_number_words(text) * 3)\n",
    "    if nrOfTokens > 13000:\n",
    "        nrOfTokens = 13000\n",
    "    return nrOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/1-introduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving chat response (start, maxtokens=330)\n",
      "- Actual total usage token=779\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=975\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/2-provision-resource\n",
      "- Retrieving chat response (between, maxtokens=765)\n",
      "- Actual total usage token=2031\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=3247\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/3-detect-language\n",
      "- Retrieving chat response (between, maxtokens=1401)\n",
      "- Actual total usage token=1581\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1726\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/4-extract-key-phrases\n",
      "- Retrieving chat response (between, maxtokens=240)\n",
      "- Actual total usage token=1102\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1625\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/5-analyze-sentiment\n",
      "- Retrieving chat response (between, maxtokens=561)\n",
      "- Actual total usage token=1092\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1352\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/6-extract-entities\n",
      "- Retrieving chat response (between, maxtokens=291)\n",
      "- Actual total usage token=1130\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1540\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/7-extract-linked-entities\n",
      "- Retrieving chat response (finish, maxtokens=411)\n",
      "- Actual total usage token=1135\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1531\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=363)\n",
      "- Actual total usage token=638\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=628\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/2-understand-question-answer-capability\n",
      "- Retrieving chat response (between, maxtokens=465)\n",
      "- Actual total usage token=1340\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1819\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/3-compare-to-language-understanding\n",
      "- Retrieving chat response (between, maxtokens=726)\n",
      "- Actual total usage token=1197\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1471\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/4-create-knowledge-base\n",
      "- Retrieving chat response (between, maxtokens=570)\n",
      "- Actual total usage token=1118\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1369\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/5-implement-multi-turn-conversation\n",
      "- Retrieving chat response (between, maxtokens=660)\n",
      "- Actual total usage token=1210\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1468\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/6-test-publish-knowledge-base\n",
      "- Retrieving chat response (between, maxtokens=408)\n",
      "- Actual total usage token=637\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=354\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/7-consume-client-interfaces\n",
      "- Retrieving chat response (between, maxtokens=348)\n",
      "- Actual total usage token=1079\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1504\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/8-implement-active-learning\n",
      "- Retrieving chat response (finish, maxtokens=1110)\n",
      "- Actual total usage token=1664\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1754\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=702)\n",
      "- Actual total usage token=892\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=766\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/2a-understand-prebuilt-capabilities\n",
      "- Retrieving chat response (between, maxtokens=2610)\n",
      "- Actual total usage token=2195\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1763\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/2-understand-resources-for-building\n",
      "- Retrieving chat response (between, maxtokens=3360)\n",
      "- Actual total usage token=2530\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1743\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/3-define-intents-utterances-entities\n",
      "- Retrieving chat response (between, maxtokens=2130)\n",
      "- Actual total usage token=2013\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1791\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/4-use-patterns-differentiate-similar-utterances\n",
      "- Retrieving chat response (between, maxtokens=663)\n",
      "- Actual total usage token=1229\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1417\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/5-use-pre-built-entity-components\n",
      "- Retrieving chat response (between, maxtokens=462)\n",
      "- Actual total usage token=996\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1057\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/6-train-test-publish-review\n",
      "- Retrieving chat response (finish, maxtokens=360)\n",
      "- Actual total usage token=1024\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1346\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-text-classification/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=348)\n",
      "- Actual total usage token=763\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=926\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-text-classification/2-understand-types-of-classification-projects\n",
      "- Retrieving chat response (between, maxtokens=2100)\n",
      "- Actual total usage token=1831\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1495\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-text-classification/3-understand-how-to-build-projects\n",
      "- Retrieving chat response (finish, maxtokens=4638)\n",
      "- Actual total usage token=3091\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2180\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-name-entity-extraction/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=408)\n",
      "- Actual total usage token=739\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=779\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-name-entity-extraction/2-understand-custom-named\n",
      "- Retrieving chat response (between, maxtokens=3471)\n",
      "- Actual total usage token=2537\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1785\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-name-entity-extraction/3-tag-your-data\n",
      "- Retrieving chat response (between, maxtokens=1065)\n",
      "- Actual total usage token=1311\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1275\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/custom-name-entity-extraction/4-train-evaluate-your-model\n",
      "- Retrieving chat response (finish, maxtokens=1191)\n",
      "- Actual total usage token=1620\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1825\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-text-with-translator-service/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=246)\n",
      "- Actual total usage token=616\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=682\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-text-with-translator-service/2-provision-translator-resource\n",
      "- Retrieving chat response (between, maxtokens=702)\n",
      "- Actual total usage token=1343\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1725\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-text-with-translator-service/3-understand-language-detection-translation-transliteration\n",
      "- Retrieving chat response (between, maxtokens=780)\n",
      "- Actual total usage token=1432\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1857\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-text-with-translator-service/4-specify-translation-options\n",
      "- Retrieving chat response (between, maxtokens=1125)\n",
      "- Actual total usage token=1627\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1734\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-text-with-translator-service/5-define-custom-translations\n",
      "- Retrieving chat response (finish, maxtokens=1275)\n",
      "- Actual total usage token=1715\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1817\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=774)\n",
      "- Actual total usage token=848\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=710\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/2-create-speech-service\n",
      "- Retrieving chat response (between, maxtokens=333)\n",
      "- Actual total usage token=1069\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1491\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/3-speech-to-text\n",
      "- Retrieving chat response (between, maxtokens=1212)\n",
      "- Actual total usage token=989\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=328\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/4-text-to-speech\n",
      "- Retrieving chat response (between, maxtokens=1134)\n",
      "- Actual total usage token=1457\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1483\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/5-audio-format-voices\n",
      "- Retrieving chat response (between, maxtokens=687)\n",
      "- Actual total usage token=763\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=340\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/6-speech-synthesis-markup\n",
      "- Retrieving chat response (finish, maxtokens=705)\n",
      "- Actual total usage token=1491\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1898\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-speech-speech-service/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=390)\n",
      "- Actual total usage token=670\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=675\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-speech-speech-service/2-speech-service\n",
      "- Retrieving chat response (between, maxtokens=417)\n",
      "- Actual total usage token=1112\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1535\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-speech-speech-service/3-translate-speech-text\n",
      "- Retrieving chat response (between, maxtokens=873)\n",
      "- Actual total usage token=857\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=330\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/translate-speech-speech-service/4-synthesize-translation\n",
      "- Retrieving chat response (finish, maxtokens=738)\n",
      "- Actual total usage token=1413\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1707\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(\"temp\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Directory not found\")\n",
    "finally:\n",
    "    os.mkdir(\"temp\")\n",
    "\n",
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "    os.mkdir(f\"temp/{lp['learning_path']}\")\n",
    "    lpindex = 0\n",
    "    for module in lp[\"learning_modules\"]:\n",
    "        os.mkdir(f\"temp/{lp['learning_path']}/{module['learning_module']}\")\n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            if index == 0:\n",
    "                action = \"start\"\n",
    "            elif index == len(module[\"learning_units\"]) - 1:\n",
    "                action = \"finish\"\n",
    "            else:\n",
    "                action = \"between\"\n",
    "            \n",
    "            markdown = get_markdown(url, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.md\")\n",
    "            transcript = get_chat_response(action, markdown, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.transcript.txt\", calculate_approx_tokens(markdown))\n",
    "            ssml = get_chat_response(\"ssml\", transcript, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.ssml.xml\")\n",
    "            #audio = get_audio(ssml, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.mp3\")\n",
    "\n",
    "            #break\n",
    "\n",
    "        lpindex = lpindex + 1\n",
    "        #combineAudio(f\"temp/{lp['learning_path']}/{module['learning_module']}\", \"output\", f\"{code}.{lpindex}-{module['learning_module']}\")\n",
    "\n",
    "        #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/1-introduction.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/2-provision-resource.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/3-detect-language.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/4-extract-key-phrases.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/5-analyze-sentiment.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/6-extract-entities.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language/7-extract-linked-entities.mp3\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\1-introduction.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\2-provision-resource.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\3-detect-language.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\4-extract-key-phrases.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\5-analyze-sentiment.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\6-extract-entities.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Analyze text with Azure AI Language\\\\7-extract-linked-entities.mp3', 'media/finish.mp3']\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/1-introduction.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/2-understand-question-answer-capability.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/3-compare-to-language-understanding.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/4-create-knowledge-base.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/5-implement-multi-turn-conversation.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/6-test-publish-knowledge-base.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/7-consume-client-interfaces.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution/8-implement-active-learning.mp3\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\1-introduction.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\2-understand-question-answer-capability.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\3-compare-to-language-understanding.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\4-create-knowledge-base.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\5-implement-multi-turn-conversation.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\6-test-publish-knowledge-base.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\7-consume-client-interfaces.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a question answering solution\\\\8-implement-active-learning.mp3', 'media/finish.mp3']\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/1-introduction.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/2a-understand-prebuilt-capabilities.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/2-understand-resources-for-building.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/3-define-intents-utterances-entities.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/4-use-patterns-differentiate-similar-utterances.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/5-use-pre-built-entity-components.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model/6-train-test-publish-review.mp3\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\1-introduction.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\2-understand-resources-for-building.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\2a-understand-prebuilt-capabilities.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\3-define-intents-utterances-entities.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\4-use-patterns-differentiate-similar-utterances.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\5-use-pre-built-entity-components.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Build a conversational language understanding model\\\\6-train-test-publish-review.mp3', 'media/finish.mp3']\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom text classification solution/1-introduction.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom text classification solution/2-understand-types-of-classification-projects.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom text classification solution/3-understand-how-to-build-projects.mp3\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom text classification solution\\\\1-introduction.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom text classification solution\\\\2-understand-types-of-classification-projects.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom text classification solution\\\\3-understand-how-to-build-projects.mp3', 'media/finish.mp3']\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution/1-introduction.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution/2-understand-custom-named.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution/3-tag-your-data.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution/4-train-evaluate-your-model.mp3\n",
      "- Combining audio files ['media\\\\start.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution\\\\1-introduction.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution\\\\2-understand-custom-named.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution\\\\3-tag-your-data.mp3', 'media\\\\break.mp3', 'temp/Develop natural language processing solutions with Azure AI Services/Create a custom named entity extraction solution\\\\4-train-evaluate-your-model.mp3', 'media/finish.mp3']\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Translate text with Azure AI Translator service/1-introduction.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Translate text with Azure AI Translator service/2-provision-translator-resource.mp3\n",
      "- Creating audio temp/Develop natural language processing solutions with Azure AI Services/Translate text with Azure AI Translator service/3-understand-language-detection-translation-transliteration.mp3\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 1039: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m unit_name \u001b[38;5;241m=\u001b[39m url\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ssml.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m ssml_file:\n\u001b[1;32m---> 14\u001b[0m     ssml \u001b[38;5;241m=\u001b[39m ssml_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlpindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     17\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlpindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 1039: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "    lpindex = 0\n",
    "    for module in lp[\"learning_modules\"]:\n",
    "        lpindex = lpindex + 1  \n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            with open(f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.ssml.xml\", \"r\") as ssml_file:\n",
    "                ssml = ssml_file.read()\n",
    "\n",
    "            if not os.path.exists(f\"output/{code}.{lpindex}-{module['learning_module']}\"):\n",
    "                os.makedirs(f\"output/{code}.{lpindex}-{module['learning_module']}\")\n",
    "\n",
    "            source_file = f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.ssml.xml\"\n",
    "            destination_file = f\"output/{code}.{lpindex}-{module['learning_module']}/{unit_name}.ssml.xml\"\n",
    "\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "            audio = get_audio(ssml, f\"temp/{lp['learning_path']}/{module['learning_module']}/{unit_name}.mp3\")\n",
    "\n",
    "        combineAudio(f\"temp/{lp['learning_path']}/{module['learning_module']}\", \"output\", f\"{code}.{lpindex}-{module['learning_module']}\")\n",
    "\n",
    "        #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
