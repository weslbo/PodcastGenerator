{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Generator\n",
    "\n",
    "This notebook support the creation of a podcast .mp3 audio file.\n",
    "\n",
    "When you listen to the generated podcast, you will notice an engaging conversation between the host and a guest, as they talk about the content of your choice. You determine what they talk about, as you can provide a list of web pages to take content from.\n",
    "\n",
    "The podcast generator uses the following technique to create the .mp3:\n",
    "\n",
    "1. Define a list of url's you want to use as the input for the podcast content. The generator will automatically fetch the content of these web pages and translate to markdown language\n",
    "2. Define who are the host and the guest\n",
    "3. For each web page, generate a podcast transcript (where the host and the guest have a conversation). This uses Azure OpenAI gpt3.5 deployed model.\n",
    "4. Transform the podcast transcript to SSML (Speech Synthesis Markup Language)\n",
    "5. Transform the SSML output to audio using Azure Cognitive Service Speech API\n",
    "6. Combine all the .mp3 files into one output\n",
    "\n",
    "Let's first get started by installing the pre-requisites (pip install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the name of the host and the guest. For a full list of voices, check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-text-to-speech?tabs=streaming\n",
    "\n",
    "| LocalName             | ShortName                       | Gender | WordsPerMinute |\n",
    "|-----------------------|---------------------------------|--------|----------------|\n",
    "| Ava                   | en-US-AvaNeural                 | Female |                |\n",
    "| Andrew                | en-US-AndrewNeural              | Male   |                |\n",
    "| Emma                  | en-US-EmmaNeural                | Female |                |\n",
    "| Brian                 | en-US-BrianNeural               | Male   |                |\n",
    "| Jenny *               | en-US-JennyNeural               | Female | 152            |\n",
    "| Guy *                 | en-US-GuyNeural                 | Male   | 215            |\n",
    "| Aria *                | en-US-AriaNeural                | Female | 150            |\n",
    "| Davis *               | en-US-DavisNeural               | Male   | 154            |\n",
    "| Jane *                | en-US-JaneNeural                | Female | 154            |\n",
    "| Jason *               | en-US-JasonNeural               | Male   | 156            |\n",
    "| Sara *                | en-US-SaraNeural                | Female | 157            |\n",
    "| Tony *                | en-US-TonyNeural                | Male   | 156            |\n",
    "| Nancy *               | en-US-NancyNeural               | Female | 149            |\n",
    "| Amber                 | en-US-AmberNeural               | Female | 152            |\n",
    "| Ana                   | en-US-AnaNeural                 | Female | 135            |\n",
    "| Ashley                | en-US-AshleyNeural              | Female | 149            |\n",
    "| Brandon               | en-US-BrandonNeural             | Male   | 156            |\n",
    "| Christopher           | en-US-ChristopherNeural         | Male   | 149            |\n",
    "| Cora                  | en-US-CoraNeural                | Female | 146            |\n",
    "| Elizabeth             | en-US-ElizabethNeural           | Female | 152            |\n",
    "| Eric                  | en-US-EricNeural                | Male   | 147            |\n",
    "| Jacob                 | en-US-JacobNeural               | Male   | 154            |\n",
    "| Jenny Multilingual    | en-US-JennyMultilingualNeural   | Female | 190            |\n",
    "| Jenny Multilingual V2 | en-US-JennyMultilingualV2Neural | Female | 190            |\n",
    "| Michelle              | en-US-MichelleNeural            | Female | 154            |\n",
    "| Monica                | en-US-MonicaNeural              | Female | 145            |\n",
    "| Roger                 | en-US-RogerNeural               | Male   |                |\n",
    "| Ryan Multilingual     | en-US-RyanMultilingualNeural    | Male   | 190            |\n",
    "| Steffan               | en-US-SteffanNeural             | Male   | 154            |\n",
    "\n",
    "** Have styles in preview (for example, assistant, newscast, angry, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"Brian\"\n",
    "guest = \"Emma\"\n",
    "podcast_title = \"DP600, Implementing Analytics Solutions Using Microsoft Fabric\"\n",
    "code = \"DP-600\"\n",
    "learn_module = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import requests\n",
    "import markdownify\n",
    "import re\n",
    "import json\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from openai import AzureOpenAI\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve markdown text for a URL\n",
    "\n",
    "The following function will download the page content from the URL parameter. \n",
    "\n",
    "- It will then find the div with id `unit-inner-section`. \n",
    "- Next, it removes some metadata from the HTML. \n",
    "- Finally, the returning text will be transformed to markdown content as the return value for this function. Markdown is a bit easier to work with when using it as input for gpt model (as it will preserve headers, ...)\n",
    "- The function will also store the markdown content in the output folder (mainly for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markdown(url, savelocation):\n",
    "    print(\"- Retrieving markdown from \" + url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # might need to adapt this when working with other web pages (not Microsoft Learn)\n",
    "    div = soup.find(id=\"unit-inner-section\")\n",
    "\n",
    "    for ul in div.find_all(\"ul\", class_=\"metadata\"):\n",
    "        ul.decompose()\n",
    "    for d in div.find_all(\"div\", class_=\"xp-tag\"):\n",
    "        d.decompose()\n",
    "    for next in div.find_all(\"div\", class_=\"next-section\"):\n",
    "        next.decompose()\n",
    "    for header in div.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "        header.string = \"\\n# \" + header.get_text() + \"\\n\"\n",
    "    for code in div.find_all(\"code\"):\n",
    "        code.decompose()\n",
    "\n",
    "    markdown = markdownify.markdownify(str(div), heading_style=\"ATX\", bullets=\"-\")\n",
    "    markdown = re.sub('\\n{3,}', '\\n\\n', markdown)\n",
    "    markdown = markdown.replace(\"[Continue](/en-us/)\", \"\")\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(markdown)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Azure OpenAI chat response\n",
    "\n",
    "This function will call the Azure OpenAI GPT model. Follow these steps:\n",
    "\n",
    "1. Deploy an Azure OpenAI Service resource (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)\n",
    "2. Deploy a model \"gpt-35-turbo-16k\". If possible, you can also deploy \"gpt-4-32k\" if quota is available. The more tokens you have, the less issues you will experience when calling the chat service. (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model)\n",
    "3. Retrieve the OPENAI_API_KEY and store it in the .env file\n",
    "\n",
    "The following code makes use op some predefined prompts. The idea is that every webpage (markdown) will be attached as content when asking the gpt model to generate a podcast transcript. Since we want the transcript opening and closing section to be different, we have multiple prompts.\n",
    "\n",
    "Notice that the characters of the host and guest are defined in another template.\n",
    "\n",
    "For troubleshooting purposes, the output of the chat completion is also stored as a file in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(action, content, savelocation, maxtokens=13000, userMessage=\"Generate the podcast\"):\n",
    "    print(f\"- Retrieving chat response ({action}, maxtokens={maxtokens})\")\n",
    "    client = AzureOpenAI(azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"), api_version=\"2023-07-01-preview\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    with open(\"prompts/prompt_characters.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt_characters = text_file.read()\n",
    "\n",
    "    with open(f\"prompts/prompt_{action}.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt = text_file.read()\n",
    "\n",
    "    prompt = prompt.replace(\"{characters}\", prompt_characters)\n",
    "    prompt = prompt.replace(\"{host}\", host)\n",
    "    prompt = prompt.replace(\"{guest}\", guest)\n",
    "    prompt = prompt.replace(\"{content}\", content)\n",
    "    prompt = prompt.replace(\"{podcast_title}\", podcast_title)\n",
    "\n",
    "    message_text = [\n",
    "        {\"role\":\"system\",\"content\":prompt},\n",
    "        {\"role\":\"user\",\"content\":userMessage}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-16k\",\n",
    "        messages = message_text,\n",
    "        temperature=0.1,\n",
    "        #max_tokens=13000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    print(f\"- Actual total usage token={completion.usage.total_tokens}\")\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MP3 audio\n",
    "\n",
    "The following function takes the SSML transcript and uses the Azure Speech Service to transform the text into speech.\n",
    "\n",
    "1. You will need to deploy an Azure Speech Service. Check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-text-to-speech for more information.\n",
    "2. Fetch the SPEECH_API_KEY and store in the .env file.\n",
    "\n",
    "As a result, an .mp3 file will be created in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(ssml, savelocation):\n",
    "    print(f\"- Creating audio {savelocation}\")\n",
    "    \n",
    "    service_region = \"eastus\"\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3)  \n",
    "\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=savelocation)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)  \n",
    "\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append multiple mp3 files\n",
    "\n",
    "Since we have multiple .mp3 files, we want to merge/append them together sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the combined podcast .mp3 file\n",
    "\n",
    "This code will first get a list of all the generated .mp3 files, and combine them with a couple of short audio tunes to indicate start, break and finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineAudio(templocation, savelocation):\n",
    "    input_files = fnmatch.filter(os.listdir(templocation), '*.mp3')\n",
    "    final_files = []\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        input_files[i] = os.path.join(templocation, input_files[i])\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        if i == 0:\n",
    "            final_files.append(\"media\\\\start.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "        elif i == len(input_files) - 1:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "            final_files.append(\"media/finish.mp3\")\n",
    "        elif i == 1:\n",
    "            final_files.append(input_files[i]) # skip the first break (as the introduction is only a few minutes long)\n",
    "        else:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "\n",
    "    print(\"- Combining audio files \" + str(final_files))\n",
    "    \n",
    "    # Initialize an empty AudioSegment\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through input files and append them to the combined_audio\n",
    "    for input_file in final_files:\n",
    "        audio_segment = AudioSegment.from_file(input_file, format=\"mp3\")\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Export the combined audio to the output file\n",
    "    combined_audio.export(savelocation, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text): \n",
    "    nrOfWords = len(text.split())\n",
    "    return nrOfWords\n",
    "\n",
    "def calculate_approx_tokens(text):\n",
    "    nrOfTokens = round(calculate_number_words(text) * 3)\n",
    "    if nrOfTokens > 13000:\n",
    "        nrOfTokens = 13000\n",
    "    return nrOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=570)\n",
      "- Actual total usage token=1190\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1651\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/2-dataflows-gen-2\n",
      "- Retrieving chat response (between, maxtokens=1800)\n",
      "- Actual total usage token=1766\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1673\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/3-explore-dataflows-gen-2\n",
      "- Retrieving chat response (between, maxtokens=1206)\n",
      "- Actual total usage token=1680\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1895\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/4-dataflow-pipeline\n",
      "- Retrieving chat response (finish, maxtokens=507)\n",
      "- Actual total usage token=1312\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1808\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=420)\n",
      "- Actual total usage token=734\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=826\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/2-connect-authenticate\n",
      "- Retrieving chat response (between, maxtokens=1161)\n",
      "- Actual total usage token=1661\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2004\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/3-write-optimize\n",
      "- Retrieving chat response (between, maxtokens=840)\n",
      "- Actual total usage token=1203\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1183\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/ingest-data-with-spark-fabric-notebooks/4-considerations\n",
      "- Retrieving chat response (finish, maxtokens=579)\n",
      "- Actual total usage token=1301\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1766\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=384)\n",
      "- Actual total usage token=755\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=898\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/2-understand-fabric-pipeline\n",
      "- Retrieving chat response (between, maxtokens=1263)\n",
      "- Actual total usage token=1335\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1183\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/3-copy-data\n",
      "- Retrieving chat response (between, maxtokens=1041)\n",
      "- Actual total usage token=1365\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1397\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/4-pipeline-templates\n",
      "- Retrieving chat response (between, maxtokens=378)\n",
      "- Actual total usage token=977\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1184\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/5-run-monitor-pipelines\n",
      "- Retrieving chat response (finish, maxtokens=432)\n",
      "- Actual total usage token=993\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1128\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/introduction-end-analytics-use-microsoft-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=321)\n",
      "- Actual total usage token=787\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1014\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/introduction-end-analytics-use-microsoft-fabric/2-explore-analytics-fabric\n",
      "- Retrieving chat response (between, maxtokens=2163)\n",
      "- Actual total usage token=1924\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1510\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/introduction-end-analytics-use-microsoft-fabric/3-data-team\n",
      "- Retrieving chat response (between, maxtokens=972)\n",
      "- Actual total usage token=1439\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1753\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/introduction-end-analytics-use-microsoft-fabric/4-use-fabric\n",
      "- Retrieving chat response (finish, maxtokens=1893)\n",
      "- Actual total usage token=2007\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1828\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-lakehouses/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=531)\n",
      "- Actual total usage token=1010\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1299\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-lakehouses/2-fabric-lakehouse\n",
      "- Retrieving chat response (between, maxtokens=1308)\n",
      "- Actual total usage token=1624\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1745\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-lakehouses/3-work-lakehouse\n",
      "- Retrieving chat response (between, maxtokens=1452)\n",
      "- Actual total usage token=1590\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1426\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-lakehouses/4-explore-data-lakehouse\n",
      "- Retrieving chat response (finish, maxtokens=918)\n",
      "- Actual total usage token=1393\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1632\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=345)\n",
      "- Actual total usage token=667\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=744\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/2-spark\n",
      "- Retrieving chat response (between, maxtokens=1227)\n",
      "- Actual total usage token=1592\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1865\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/3-spark-code\n",
      "- Retrieving chat response (between, maxtokens=630)\n",
      "- Actual total usage token=1011\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1000\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/4-dataframe\n",
      "- Retrieving chat response (between, maxtokens=3543)\n",
      "- Actual total usage token=2603\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1728\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/5-spark-sql\n",
      "- Retrieving chat response (between, maxtokens=1713)\n",
      "- Actual total usage token=1611\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1495\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/6-visualize-data\n",
      "- Retrieving chat response (finish, maxtokens=1167)\n",
      "- Actual total usage token=1550\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1779\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/work-delta-lake-tables-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=447)\n",
      "- Actual total usage token=764\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=878\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/work-delta-lake-tables-fabric/2-understand-delta-lake\n",
      "- Retrieving chat response (between, maxtokens=1140)\n",
      "- Actual total usage token=1436\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1439\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/work-delta-lake-tables-fabric/3-create-delta-tables\n",
      "- Retrieving chat response (between, maxtokens=2610)\n",
      "- Actual total usage token=2243\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2277\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/work-delta-lake-tables-fabric/4-work-delta-data\n",
      "- Retrieving chat response (between, maxtokens=1032)\n",
      "- Actual total usage token=1243\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1132\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/work-delta-lake-tables-fabric/5-use-delta-lake-streaming-data\n",
      "- Retrieving chat response (finish, maxtokens=1845)\n",
      "- Actual total usage token=1791\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1722\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=570)\n",
      "- Actual total usage token=768\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=762\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/2-dataflows-gen-2\n",
      "- Retrieving chat response (between, maxtokens=1800)\n",
      "- Actual total usage token=1729\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1599\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/3-explore-dataflows-gen-2\n",
      "- Retrieving chat response (between, maxtokens=1206)\n",
      "- Actual total usage token=1667\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1869\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-dataflow-gen-2-fabric/4-dataflow-pipeline\n",
      "- Retrieving chat response (finish, maxtokens=507)\n",
      "- Actual total usage token=1220\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1591\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=384)\n",
      "- Actual total usage token=1055\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1536\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/2-understand-fabric-pipeline\n",
      "- Retrieving chat response (between, maxtokens=1263)\n",
      "- Actual total usage token=1394\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1301\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/3-copy-data\n",
      "- Retrieving chat response (between, maxtokens=1041)\n",
      "- Actual total usage token=1546\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1803\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/4-pipeline-templates\n",
      "- Retrieving chat response (between, maxtokens=378)\n",
      "- Actual total usage token=999\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1249\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-data-factory-pipelines-fabric/5-run-monitor-pipelines\n",
      "- Retrieving chat response (finish, maxtokens=432)\n",
      "- Actual total usage token=1025\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1203\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/describe-medallion-architecture/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=543)\n",
      "- Actual total usage token=832\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=857\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/describe-medallion-architecture/2-describe-medallion-architecture\n",
      "- Retrieving chat response (between, maxtokens=2385)\n",
      "- Actual total usage token=2191\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1976\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/describe-medallion-architecture/3-implement-medallion-archecture-fabric\n",
      "- Retrieving chat response (between, maxtokens=1455)\n",
      "- Actual total usage token=1674\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1766\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/describe-medallion-architecture/4-query-report-data\n",
      "- Retrieving chat response (between, maxtokens=1332)\n",
      "- Actual total usage token=1757\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2003\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/describe-medallion-architecture/5-secure-govern\n",
      "- Retrieving chat response (finish, maxtokens=1437)\n",
      "- Actual total usage token=1679\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1690\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=570)\n",
      "- Actual total usage token=911\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1040\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/2-understand-data-warehouse\n",
      "- Retrieving chat response (between, maxtokens=3120)\n",
      "- Actual total usage token=2506\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2066\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/3-understand-data-warehouse-fabric\n",
      "- Retrieving chat response (between, maxtokens=2286)\n",
      "- Actual total usage token=1980\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1681\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/4-query-transform-data\n",
      "- Retrieving chat response (between, maxtokens=873)\n",
      "- Actual total usage token=1354\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1544\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/5-model-data\n",
      "- Retrieving chat response (between, maxtokens=2178)\n",
      "- Actual total usage token=2274\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2207\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/get-started-data-warehouse/6-security-monitor\n",
      "- Retrieving chat response (finish, maxtokens=1776)\n",
      "- Actual total usage token=1878\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1939\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/load-data-into-microsoft-fabric-data-warehouse/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=1158)\n",
      "- Actual total usage token=1113\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=789\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/load-data-into-microsoft-fabric-data-warehouse/2-explore-data-load-strategies\n",
      "- Retrieving chat response (between, maxtokens=3291)\n",
      "- Actual total usage token=1962\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=332\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/load-data-into-microsoft-fabric-data-warehouse/3-load-data-using-data-pipeline\n",
      "- Retrieving chat response (between, maxtokens=1773)\n",
      "- Actual total usage token=1905\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1624\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/load-data-into-microsoft-fabric-data-warehouse/4-load-data-using-tsql\n",
      "- Retrieving chat response (between, maxtokens=2196)\n",
      "- Actual total usage token=1975\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1569\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/load-data-into-microsoft-fabric-data-warehouse/5-load-data-using-dataflow\n",
      "- Retrieving chat response (finish, maxtokens=1863)\n",
      "- Actual total usage token=2197\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2124\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/query-data-warehouse-microsoft-fabric/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=987)\n",
      "- Actual total usage token=1303\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1300\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/query-data-warehouse-microsoft-fabric/2-use-sql-query-editor\n",
      "- Retrieving chat response (between, maxtokens=1311)\n",
      "- Actual total usage token=1454\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1263\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/query-data-warehouse-microsoft-fabric/3-explore-visual-query-editor\n",
      "- Retrieving chat response (between, maxtokens=813)\n",
      "- Actual total usage token=1244\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1365\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/query-data-warehouse-microsoft-fabric/4-use-client-tools\n",
      "- Retrieving chat response (finish, maxtokens=789)\n",
      "- Actual total usage token=1258\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1356\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/monitor-fabric-data-warehouse/01-introduction\n",
      "- Retrieving chat response (start, maxtokens=210)\n",
      "- Actual total usage token=658\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=842\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/monitor-fabric-data-warehouse/02-capacity-metrics\n",
      "- Retrieving chat response (between, maxtokens=804)\n",
      "- Actual total usage token=1218\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1349\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/monitor-fabric-data-warehouse/03-dynamic-management-views\n",
      "- Retrieving chat response (between, maxtokens=675)\n",
      "- Actual total usage token=1370\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1473\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/monitor-fabric-data-warehouse/04-query-insights\n",
      "- Retrieving chat response (finish, maxtokens=834)\n",
      "- Actual total usage token=1415\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1727\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/understand-scalability-power-bi/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=330)\n",
      "- Actual total usage token=857\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1151\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/understand-scalability-power-bi/2-describe-significance-of-scalable-models\n",
      "- Retrieving chat response (between, maxtokens=1719)\n",
      "- Actual total usage token=1739\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1347\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/understand-scalability-power-bi/3-implement-data-modeling-best-practices\n",
      "- Retrieving chat response (between, maxtokens=2637)\n",
      "- Actual total usage token=2176\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1371\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/understand-scalability-power-bi/4-configure-large-datasets\n",
      "- Retrieving chat response (finish, maxtokens=1380)\n",
      "- Actual total usage token=1831\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2062\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=399)\n",
      "- Actual total usage token=1193\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1828\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/2-understand-model-relationships\n",
      "- Retrieving chat response (between, maxtokens=1929)\n",
      "- Actual total usage token=1677\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1184\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/3-set-up-relationships\n",
      "- Retrieving chat response (between, maxtokens=4377)\n",
      "- Actual total usage token=3163\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1719\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/4-use-dax-relationship-functions\n",
      "- Retrieving chat response (between, maxtokens=951)\n",
      "- Actual total usage token=968\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=316\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/5-understand-relationship-evaluation\n",
      "- Retrieving chat response (finish, maxtokens=3570)\n",
      "- Actual total usage token=2808\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1904\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=501)\n",
      "- Actual total usage token=822\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=896\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/2-use-performance-analyzer\n",
      "- Retrieving chat response (between, maxtokens=3339)\n",
      "- Actual total usage token=2629\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1919\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/3-troubleshoot-dax-performance-use-dax-studio\n",
      "- Retrieving chat response (between, maxtokens=3954)\n",
      "- Actual total usage token=2900\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1725\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/4-optimize-data-model-use-best-practice-analyzer\n",
      "- Retrieving chat response (finish, maxtokens=2826)\n",
      "- Actual total usage token=2587\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1940\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=384)\n",
      "- Actual total usage token=1006\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1400\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/2-restrict-access-to-power-bi-model-data\n",
      "- Retrieving chat response (between, maxtokens=4137)\n",
      "- Actual total usage token=3218\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2017\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/3-restrict-access-to-power-bi-model-objects\n",
      "- Retrieving chat response (between, maxtokens=2538)\n",
      "- Actual total usage token=2369\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1777\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/4-apply-good-modeling-practices\n",
      "- Retrieving chat response (finish, maxtokens=480)\n",
      "- Actual total usage token=1249\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1827\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=399)\n",
      "- Actual total usage token=1235\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1956\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/2-understand-model-relationships\n",
      "- Retrieving chat response (between, maxtokens=1929)\n",
      "- Actual total usage token=2050\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1985\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/3-set-up-relationships\n",
      "- Retrieving chat response (between, maxtokens=4377)\n",
      "- Actual total usage token=3501\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2417\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/4-use-dax-relationship-functions\n",
      "- Retrieving chat response (between, maxtokens=951)\n",
      "- Actual total usage token=968\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=316\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-power-bi-model-relationships/5-understand-relationship-evaluation\n",
      "- Retrieving chat response (finish, maxtokens=3570)\n",
      "- Actual total usage token=2615\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1495\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/dax-power-bi-time-intelligence/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=786)\n",
      "- Actual total usage token=964\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=870\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/dax-power-bi-time-intelligence/2-functions\n",
      "- Retrieving chat response (between, maxtokens=3114)\n",
      "- Actual total usage token=2672\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2106\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/dax-power-bi-time-intelligence/3-calculations\n",
      "- Retrieving chat response (between, maxtokens=3495)\n",
      "- Actual total usage token=3175\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2713\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/dax-power-bi-time-intelligence/3b-lab\n",
      "- Retrieving chat response (between, maxtokens=552)\n",
      "- Actual total usage token=1278\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1611\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/dax-power-bi-time-intelligence/4-check\n",
      "- Retrieving chat response (finish, maxtokens=579)\n",
      "- Actual total usage token=1143\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1407\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-calculation-groups/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=465)\n",
      "- Actual total usage token=690\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=685\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-calculation-groups/2-understand\n",
      "- Retrieving chat response (between, maxtokens=1119)\n",
      "- Actual total usage token=1523\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1617\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-calculation-groups/3-explore-usage-features\n",
      "- Retrieving chat response (between, maxtokens=1254)\n",
      "- Actual total usage token=1504\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1436\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-calculation-groups/4-model\n",
      "- Retrieving chat response (between, maxtokens=1002)\n",
      "- Actual total usage token=1282\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1129\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-calculation-groups/5-lab\n",
      "- Retrieving chat response (finish, maxtokens=237)\n",
      "- Actual total usage token=1289\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2030\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=384)\n",
      "- Actual total usage token=896\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1158\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/2-restrict-access-to-power-bi-model-data\n",
      "- Retrieving chat response (between, maxtokens=4137)\n",
      "- Actual total usage token=3266\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2069\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/3-restrict-access-to-power-bi-model-objects\n",
      "- Retrieving chat response (between, maxtokens=2538)\n",
      "- Actual total usage token=2487\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2036\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/enforce-power-bi-model-security/4-apply-good-modeling-practices\n",
      "- Retrieving chat response (finish, maxtokens=480)\n",
      "- Actual total usage token=1145\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1562\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=501)\n",
      "- Actual total usage token=831\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=914\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/2-use-performance-analyzer\n",
      "- Retrieving chat response (between, maxtokens=3339)\n",
      "- Actual total usage token=2543\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1725\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/3-troubleshoot-dax-performance-use-dax-studio\n",
      "- Retrieving chat response (between, maxtokens=3954)\n",
      "- Actual total usage token=2946\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1807\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/use-tools-optimize-power-bi-performance/4-optimize-data-model-use-best-practice-analyzer\n",
      "- Retrieving chat response (finish, maxtokens=2826)\n",
      "- Actual total usage token=2645\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2089\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/design-power-bi-application-lifecycle-management-strategy/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=576)\n",
      "- Actual total usage token=925\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1100\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/design-power-bi-application-lifecycle-management-strategy/2-define\n",
      "- Retrieving chat response (between, maxtokens=1059)\n",
      "- Actual total usage token=1496\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1618\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/design-power-bi-application-lifecycle-management-strategy/3-recommend-source-control-strategy\n",
      "- Retrieving chat response (between, maxtokens=2022)\n",
      "- Actual total usage token=1804\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1575\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/design-power-bi-application-lifecycle-management-strategy/4-design-deployment-strategy\n",
      "- Retrieving chat response (finish, maxtokens=1911)\n",
      "- Actual total usage token=2047\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2036\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/introduction\n",
      "- Retrieving chat response (start, maxtokens=282)\n",
      "- Actual total usage token=762\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=998\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/understand-deployment-process\n",
      "- Retrieving chat response (between, maxtokens=1302)\n",
      "- Actual total usage token=1659\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1836\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/create-deployment-pipeline\n",
      "- Retrieving chat response (between, maxtokens=1047)\n",
      "- Actual total usage token=1274\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1173\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/assign-workspace\n",
      "- Retrieving chat response (between, maxtokens=1134)\n",
      "- Actual total usage token=1354\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1234\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/deploy-content\n",
      "- Retrieving chat response (between, maxtokens=1284)\n",
      "- Actual total usage token=1488\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1555\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/work-with-deployment-pipelines\n",
      "- Retrieving chat response (between, maxtokens=3009)\n",
      "- Actual total usage token=2435\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=2157\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/power-bi-deployment-pipelines/check\n",
      "- Retrieving chat response (finish, maxtokens=927)\n",
      "- Actual total usage token=1367\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1692\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-manage-power-bi-assets/1-introduction\n",
      "- Retrieving chat response (start, maxtokens=579)\n",
      "- Actual total usage token=879\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=951\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-manage-power-bi-assets/2-create-reusable\n",
      "- Retrieving chat response (between, maxtokens=2223)\n",
      "- Actual total usage token=2036\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1609\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-manage-power-bi-assets/3-explore-use-lineage-view\n",
      "- Retrieving chat response (between, maxtokens=1512)\n",
      "- Actual total usage token=1757\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1681\n",
      "- Retrieving markdown from https://learn.microsoft.com/en-us/training/modules/create-manage-power-bi-assets/4-dataset-use-xmla-endpoint\n",
      "- Retrieving chat response (finish, maxtokens=1041)\n",
      "- Actual total usage token=1439\n",
      "- Retrieving chat response (ssml, maxtokens=13000)\n",
      "- Actual total usage token=1547\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "\n",
    "    modules = [module for module in lp[\"learning_modules\"] if module[\"learning_module\"] == learn_module or learn_module == \"all\"]\n",
    "    for module in modules:\n",
    "        outputFolder_module = f\"output/{code}.{module['learning_module']}\"\n",
    "        outputFile_module_mp3 = f\"output/{code}.{module['learning_module']}.mp3\"\n",
    "\n",
    "        if not os.path.exists(outputFolder_module):\n",
    "            os.mkdir(outputFolder_module)\n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            if index == 0:\n",
    "                action = \"start\"\n",
    "            elif index == len(module[\"learning_units\"]) - 1:\n",
    "                action = \"finish\"\n",
    "            else:\n",
    "                action = \"between\"\n",
    "            \n",
    "            outputFile_md = f\"{outputFolder_module}/{unit_name}.md\"\n",
    "            outpufFile_transcript = f\"{outputFolder_module}/{unit_name}.transcript.txt\"\n",
    "            outputFile_ssml = f\"{outputFolder_module}/{unit_name}.ssml.xml\"\n",
    "            outputFile_unit_mp3 = f\"{outputFolder_module}/{unit_name}.mp3\"\n",
    "            \n",
    "            markdown = get_markdown(url, outputFile_md)\n",
    "            transcript = get_chat_response(action, markdown, outpufFile_transcript, calculate_approx_tokens(markdown))\n",
    "            ssml = get_chat_response(\"ssml\", transcript, outputFile_ssml)\n",
    "            #audio = get_audio(ssml, outputFile_unit_mp3)\n",
    "\n",
    "            #break\n",
    "\n",
    "        #combineAudio(outputFolder_module , outputFile_module_mp3)\n",
    "\n",
    "        #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Creating audio output/AI-3004.Analyze images/1-introduction.mp3\n",
      "- Creating audio output/AI-3004.Analyze images/2-provision-computer-vision-resource.mp3\n",
      "- Creating audio output/AI-3004.Analyze images/3-analyze-image.mp3\n",
      "- Creating audio output/AI-3004.Analyze images/4-generate-smart-cropped-thumbnail.mp3\n",
      "- Combining audio files ['media\\\\start.mp3', 'output/AI-3004.Analyze images\\\\1-introduction.mp3', 'output/AI-3004.Analyze images\\\\2-provision-computer-vision-resource.mp3', 'media\\\\break.mp3', 'output/AI-3004.Analyze images\\\\3-analyze-image.mp3', 'media\\\\break.mp3', 'output/AI-3004.Analyze images\\\\4-generate-smart-cropped-thumbnail.mp3', 'media/finish.mp3']\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "\n",
    "    modules = [module for module in lp[\"learning_modules\"] if module[\"learning_module\"] == learn_module or learn_module == \"all\"]\n",
    "    for module in modules:\n",
    "        outputFolder_module = f\"output/{code}.{module['learning_module']}\"\n",
    "        outputFile_module_mp3 = f\"output/{code}.{module['learning_module']}.mp3\"\n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            outputFile_ssml = f\"{outputFolder_module}/{unit_name}.ssml.xml\"\n",
    "            outputFile_unit_mp3 = f\"{outputFolder_module}/{unit_name}.mp3\"\n",
    "\n",
    "            with open(outputFile_ssml, \"r\", encoding=\"utf8\") as ssml_file:\n",
    "                ssml = ssml_file.read()\n",
    "            \n",
    "            audio = get_audio(ssml, outputFile_unit_mp3)\n",
    "\n",
    "            #break\n",
    "\n",
    "        combineAudio(outputFolder_module , outputFile_module_mp3)\n",
    "\n",
    "        #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\\AI-3003.Analyze text with Azure AI Language\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Actual total usage token=341\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\1-introduction.plantuml\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\2-provision-resource.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=551\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\2-provision-resource.plantuml\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\3-detect-language.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=882\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\3-detect-language.plantuml\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\4-extract-key-phrases.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=325\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\4-extract-key-phrases.plantuml\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\5-analyze-sentiment.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=478\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\5-analyze-sentiment.plantuml\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\6-extract-entities.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=374\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\6-extract-entities.plantuml\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\7-extract-linked-entities.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=455\n",
      "output\\AI-3003.Analyze text with Azure AI Language\\7-extract-linked-entities.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=531\n",
      "output\\AI-3003.Build a conversational language understanding model\\1-introduction.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\2-understand-resources-for-building.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1737\n",
      "output\\AI-3003.Build a conversational language understanding model\\2-understand-resources-for-building.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\2a-understand-prebuilt-capabilities.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1377\n",
      "output\\AI-3003.Build a conversational language understanding model\\2a-understand-prebuilt-capabilities.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\3-define-intents-utterances-entities.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1293\n",
      "output\\AI-3003.Build a conversational language understanding model\\3-define-intents-utterances-entities.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\4-use-patterns-differentiate-similar-utterances.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=595\n",
      "output\\AI-3003.Build a conversational language understanding model\\4-use-patterns-differentiate-similar-utterances.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\5-use-pre-built-entity-components.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=524\n",
      "output\\AI-3003.Build a conversational language understanding model\\5-use-pre-built-entity-components.plantuml\n",
      "output\\AI-3003.Build a conversational language understanding model\\6-train-test-publish-review.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=396\n",
      "output\\AI-3003.Build a conversational language understanding model\\6-train-test-publish-review.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=373\n",
      "output\\AI-3003.Build a question answering solution\\1-introduction.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\2-understand-question-answer-capability.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=516\n",
      "output\\AI-3003.Build a question answering solution\\2-understand-question-answer-capability.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\3-compare-to-language-understanding.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=518\n",
      "output\\AI-3003.Build a question answering solution\\3-compare-to-language-understanding.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\4-create-knowledge-base.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=540\n",
      "output\\AI-3003.Build a question answering solution\\4-create-knowledge-base.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\5-implement-multi-turn-conversation.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=574\n",
      "output\\AI-3003.Build a question answering solution\\5-implement-multi-turn-conversation.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\6-test-publish-knowledge-base.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=426\n",
      "output\\AI-3003.Build a question answering solution\\6-test-publish-knowledge-base.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\7-consume-client-interfaces.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=383\n",
      "output\\AI-3003.Build a question answering solution\\7-consume-client-interfaces.plantuml\n",
      "output\\AI-3003.Build a question answering solution\\8-implement-active-learning.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=861\n",
      "output\\AI-3003.Build a question answering solution\\8-implement-active-learning.plantuml\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=417\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\1-introduction.plantuml\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\2-understand-custom-named.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1814\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\2-understand-custom-named.plantuml\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\3-tag-your-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=726\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\3-tag-your-data.plantuml\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\4-train-evaluate-your-model.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=771\n",
      "output\\AI-3003.Create a custom named entity extraction solution\\4-train-evaluate-your-model.plantuml\n",
      "output\\AI-3003.Create a custom text classification solution\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=405\n",
      "output\\AI-3003.Create a custom text classification solution\\1-introduction.plantuml\n",
      "output\\AI-3003.Create a custom text classification solution\\2-understand-types-of-classification-projects.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1094\n",
      "output\\AI-3003.Create a custom text classification solution\\2-understand-types-of-classification-projects.plantuml\n",
      "output\\AI-3003.Create a custom text classification solution\\3-understand-how-to-build-projects.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=2165\n",
      "output\\AI-3003.Create a custom text classification solution\\3-understand-how-to-build-projects.plantuml\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=560\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\1-introduction.plantuml\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\2-create-speech-service.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=354\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\2-create-speech-service.plantuml\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\3-speech-to-text.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=892\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\3-speech-to-text.plantuml\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\4-text-to-speech.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=807\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\4-text-to-speech.plantuml\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\5-audio-format-voices.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=557\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\5-audio-format-voices.plantuml\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\6-speech-synthesis-markup.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=598\n",
      "output\\AI-3003.Create speech-enabled apps with Azure AI services\\6-speech-synthesis-markup.plantuml\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=406\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\1-introduction.plantuml\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\2-speech-service.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=404\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\2-speech-service.plantuml\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\3-translate-speech-text.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=703\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\3-translate-speech-text.plantuml\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\4-synthesize-translation.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=620\n",
      "output\\AI-3003.Translate speech with the Azure AI Speech service\\4-synthesize-translation.plantuml\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=295\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\1-introduction.plantuml\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\2-provision-translator-resource.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=554\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\2-provision-translator-resource.plantuml\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\3-understand-language-detection-translation-transliteration.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=580\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\3-understand-language-detection-translation-transliteration.plantuml\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\4-specify-translation-options.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=781\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\4-specify-translation-options.plantuml\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\5-define-custom-translations.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=950\n",
      "output\\AI-3003.Translate text with Azure AI Translator service\\5-define-custom-translations.plantuml\n",
      "output\\AI-3004.Analyze images\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=308\n",
      "output\\AI-3004.Analyze images\\1-introduction.plantuml\n",
      "output\\AI-3004.Analyze images\\2-provision-computer-vision-resource.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=607\n",
      "output\\AI-3004.Analyze images\\2-provision-computer-vision-resource.plantuml\n",
      "output\\AI-3004.Analyze images\\3-analyze-image.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=463\n",
      "output\\AI-3004.Analyze images\\3-analyze-image.plantuml\n",
      "output\\AI-3004.Analyze images\\4-generate-smart-cropped-thumbnail.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=450\n",
      "output\\AI-3004.Analyze images\\4-generate-smart-cropped-thumbnail.plantuml\n",
      "output\\AI-3004.Analyze video\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=363\n",
      "output\\AI-3004.Analyze video\\1-introduction.plantuml\n",
      "output\\AI-3004.Analyze video\\2-understand-video-indexer-capabilities.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=438\n",
      "output\\AI-3004.Analyze video\\2-understand-video-indexer-capabilities.plantuml\n",
      "output\\AI-3004.Analyze video\\3-extract-custom-insights.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=390\n",
      "output\\AI-3004.Analyze video\\3-extract-custom-insights.plantuml\n",
      "output\\AI-3004.Analyze video\\4-use-video-indexer-widgets-apis.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=541\n",
      "output\\AI-3004.Analyze video\\4-use-video-indexer-widgets-apis.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=346\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\1-introduction.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\2-identify-options-for-face-detection-analysis-identification.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=533\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\2-identify-options-for-face-detection-analysis-identification.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\3-understand-considerations-for-face-analysis.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=374\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\3-understand-considerations-for-face-analysis.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\4-detect-faces-computer-vision-service.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=389\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\4-detect-faces-computer-vision-service.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\5-understand-capabilities-of-face-service.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=744\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\5-understand-capabilities-of-face-service.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\6-compare-match-detected-faces.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=556\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\6-compare-match-detected-faces.plantuml\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\7-implement-facial-recognition.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=506\n",
      "output\\AI-3004.Detect, analyze, and recognize faces\\7-implement-facial-recognition.plantuml\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=354\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\1-introduction.plantuml\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\2-understand-custom-model-types.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=621\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\2-understand-custom-model-types.plantuml\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\3-create-custom-project.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1000\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\3-create-custom-project.plantuml\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\4-label-train-custom-model.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=829\n",
      "output\\AI-3004.Image classification with custom Azure AI Vision models\\4-label-train-custom-model.plantuml\n",
      "output\\AI-3004.Read Text in images and documents with the Azure AI Vision Service\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=509\n",
      "output\\AI-3004.Read Text in images and documents with the Azure AI Vision Service\\1-introduction.plantuml\n",
      "output\\AI-3004.Read Text in images and documents with the Azure AI Vision Service\\2-options-read-text.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=617\n",
      "output\\AI-3004.Read Text in images and documents with the Azure AI Vision Service\\2-options-read-text.plantuml\n",
      "output\\AI-3004.Read Text in images and documents with the Azure AI Vision Service\\4-use-read-api.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=433\n",
      "output\\AI-3004.Read Text in images and documents with the Azure AI Vision Service\\4-use-read-api.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\assign-workspace.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=849\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\assign-workspace.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\check.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=855\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\check.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\create-deployment-pipeline.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=708\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\create-deployment-pipeline.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\deploy-content.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=770\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\deploy-content.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=357\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\introduction.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\understand-deployment-process.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=851\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\understand-deployment-process.plantuml\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\work-with-deployment-pipelines.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1516\n",
      "output\\DP-600.Create and manage a Power BI deployment pipeline\\work-with-deployment-pipelines.plantuml\n",
      "output\\DP-600.Create and manage Power BI assets\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=443\n",
      "output\\DP-600.Create and manage Power BI assets\\1-introduction.plantuml\n",
      "output\\DP-600.Create and manage Power BI assets\\2-create-reusable.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1298\n",
      "output\\DP-600.Create and manage Power BI assets\\2-create-reusable.plantuml\n",
      "output\\DP-600.Create and manage Power BI assets\\3-explore-use-lineage-view.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1091\n",
      "output\\DP-600.Create and manage Power BI assets\\3-explore-use-lineage-view.plantuml\n",
      "output\\DP-600.Create and manage Power BI assets\\4-dataset-use-xmla-endpoint.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=846\n",
      "output\\DP-600.Create and manage Power BI assets\\4-dataset-use-xmla-endpoint.plantuml\n",
      "output\\DP-600.Create calculation groups\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=456\n",
      "output\\DP-600.Create calculation groups\\1-introduction.plantuml\n",
      "output\\DP-600.Create calculation groups\\2-understand.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=821\n",
      "output\\DP-600.Create calculation groups\\2-understand.plantuml\n",
      "output\\DP-600.Create calculation groups\\3-explore-usage-features.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=851\n",
      "output\\DP-600.Create calculation groups\\3-explore-usage-features.plantuml\n",
      "output\\DP-600.Create calculation groups\\4-model.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=758\n",
      "output\\DP-600.Create calculation groups\\4-model.plantuml\n",
      "output\\DP-600.Create calculation groups\\5-lab.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=295\n",
      "output\\DP-600.Create calculation groups\\5-lab.plantuml\n",
      "output\\DP-600.Create Power BI model relationships\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=395\n",
      "output\\DP-600.Create Power BI model relationships\\1-introduction.plantuml\n",
      "output\\DP-600.Create Power BI model relationships\\2-understand-model-relationships.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1266\n",
      "output\\DP-600.Create Power BI model relationships\\2-understand-model-relationships.plantuml\n",
      "output\\DP-600.Create Power BI model relationships\\3-set-up-relationships.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=2457\n",
      "output\\DP-600.Create Power BI model relationships\\3-set-up-relationships.plantuml\n",
      "output\\DP-600.Create Power BI model relationships\\4-use-dax-relationship-functions.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=827\n",
      "output\\DP-600.Create Power BI model relationships\\4-use-dax-relationship-functions.plantuml\n",
      "output\\DP-600.Create Power BI model relationships\\5-understand-relationship-evaluation.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1904\n",
      "output\\DP-600.Create Power BI model relationships\\5-understand-relationship-evaluation.plantuml\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=506\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\1-introduction.plantuml\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\2-define.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=797\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\2-define.plantuml\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\3-recommend-source-control-strategy.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1096\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\3-recommend-source-control-strategy.plantuml\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\4-design-deployment-strategy.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1180\n",
      "output\\DP-600.Design a Power BI application lifecycle management strategy\\4-design-deployment-strategy.plantuml\n",
      "output\\DP-600.Enforce Power BI model security\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=385\n",
      "output\\DP-600.Enforce Power BI model security\\1-introduction.plantuml\n",
      "output\\DP-600.Enforce Power BI model security\\2-restrict-access-to-power-bi-model-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=2413\n",
      "output\\DP-600.Enforce Power BI model security\\2-restrict-access-to-power-bi-model-data.plantuml\n",
      "output\\DP-600.Enforce Power BI model security\\3-restrict-access-to-power-bi-model-objects.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1639\n",
      "output\\DP-600.Enforce Power BI model security\\3-restrict-access-to-power-bi-model-objects.plantuml\n",
      "output\\DP-600.Enforce Power BI model security\\4-apply-good-modeling-practices.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=444\n",
      "output\\DP-600.Enforce Power BI model security\\4-apply-good-modeling-practices.plantuml\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=616\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\2-understand-data-warehouse.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1619\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\2-understand-data-warehouse.plantuml\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\3-understand-data-warehouse-fabric.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1380\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\3-understand-data-warehouse-fabric.plantuml\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\4-query-transform-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=671\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\4-query-transform-data.plantuml\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\5-model-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1223\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\5-model-data.plantuml\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\6-security-monitor.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1007\n",
      "output\\DP-600.Get started with data warehouses in Microsoft Fabric\\6-security-monitor.plantuml\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=415\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\2-fabric-lakehouse.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=918\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\2-fabric-lakehouse.plantuml\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\3-work-lakehouse.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=898\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\3-work-lakehouse.plantuml\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\4-explore-data-lakehouse.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=626\n",
      "output\\DP-600.Get started with lakehouses in Microsoft Fabric\\4-explore-data-lakehouse.plantuml\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=499\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\2-dataflows-gen-2.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1160\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\2-dataflows-gen-2.plantuml\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\3-explore-dataflows-gen-2.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=884\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\3-explore-dataflows-gen-2.plantuml\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\4-dataflow-pipeline.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=516\n",
      "output\\DP-600.Ingest Data with Dataflows Gen2 in Microsoft Fabric\\4-dataflow-pipeline.plantuml\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=461\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\1-introduction.plantuml\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\2-connect-authenticate.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=805\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\2-connect-authenticate.plantuml\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\3-write-optimize.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=659\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\3-write-optimize.plantuml\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\4-considerations.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=492\n",
      "output\\DP-600.Ingest data with Spark and Microsoft Fabric notebooks\\4-considerations.plantuml\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=331\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\2-explore-analytics-fabric.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1352\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\2-explore-analytics-fabric.plantuml\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\3-data-team.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=692\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\3-data-team.plantuml\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\4-use-fabric.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1128\n",
      "output\\DP-600.Introduction to end-to-end analytics using Microsoft Fabric\\4-use-fabric.plantuml\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=809\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\1-introduction.plantuml\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\2-explore-data-load-strategies.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1834\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\2-explore-data-load-strategies.plantuml\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\3-load-data-using-data-pipeline.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1319\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\3-load-data-using-data-pipeline.plantuml\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\4-load-data-using-tsql.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1300\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\4-load-data-using-tsql.plantuml\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\5-load-data-using-dataflow.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1222\n",
      "output\\DP-600.Load data into a Microsoft Fabric data warehouse\\5-load-data-using-dataflow.plantuml\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\01-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=280\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\01-introduction.plantuml\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\02-capacity-metrics.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=642\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\02-capacity-metrics.plantuml\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\03-dynamic-management-views.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=621\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\03-dynamic-management-views.plantuml\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\04-query-insights.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=611\n",
      "output\\DP-600.Monitor a Microsoft Fabric data warehouse\\04-query-insights.plantuml\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=477\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\1-introduction.plantuml\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\2-describe-medallion-architecture.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1284\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\2-describe-medallion-architecture.plantuml\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\3-implement-medallion-archecture-fabric.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=936\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\3-implement-medallion-archecture-fabric.plantuml\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\4-query-report-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=817\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\4-query-report-data.plantuml\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\5-secure-govern.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=931\n",
      "output\\DP-600.Organize a Fabric lakehouse using medallion architecture design\\5-secure-govern.plantuml\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=756\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\2-use-sql-query-editor.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=896\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\2-use-sql-query-editor.plantuml\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\3-explore-visual-query-editor.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=604\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\3-explore-visual-query-editor.plantuml\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\4-use-client-tools.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=695\n",
      "output\\DP-600.Query a data warehouse in Microsoft Fabric\\4-use-client-tools.plantuml\n",
      "output\\DP-600.Understand scalability in Power BI\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=341\n",
      "output\\DP-600.Understand scalability in Power BI\\1-introduction.plantuml\n",
      "output\\DP-600.Understand scalability in Power BI\\2-describe-significance-of-scalable-models.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1198\n",
      "output\\DP-600.Understand scalability in Power BI\\2-describe-significance-of-scalable-models.plantuml\n",
      "output\\DP-600.Understand scalability in Power BI\\3-implement-data-modeling-best-practices.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1669\n",
      "output\\DP-600.Understand scalability in Power BI\\3-implement-data-modeling-best-practices.plantuml\n",
      "output\\DP-600.Understand scalability in Power BI\\4-configure-large-datasets.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1051\n",
      "output\\DP-600.Understand scalability in Power BI\\4-configure-large-datasets.plantuml\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=400\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\2-spark.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=842\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\2-spark.plantuml\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\3-spark-code.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=495\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\3-spark-code.plantuml\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\4-dataframe.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1912\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\4-dataframe.plantuml\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\5-spark-sql.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=958\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\5-spark-sql.plantuml\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\6-visualize-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=734\n",
      "output\\DP-600.Use Apache Spark in Microsoft Fabric\\6-visualize-data.plantuml\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=392\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\2-understand-fabric-pipeline.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=741\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\2-understand-fabric-pipeline.plantuml\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\3-copy-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=741\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\3-copy-data.plantuml\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\4-pipeline-templates.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=403\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\4-pipeline-templates.plantuml\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\5-run-monitor-pipelines.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=454\n",
      "output\\DP-600.Use Data Factory pipelines in Microsoft Fabric\\5-run-monitor-pipelines.plantuml\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=622\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\1-introduction.plantuml\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\2-functions.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1706\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\2-functions.plantuml\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\3-calculations.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1894\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\3-calculations.plantuml\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\3b-lab.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=552\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\3b-lab.plantuml\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\4-check.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=516\n",
      "output\\DP-600.Use DAX time intelligence functions in Power BI Desktop models\\4-check.plantuml\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=439\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\1-introduction.plantuml\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\2-use-performance-analyzer.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1788\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\2-use-performance-analyzer.plantuml\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\3-troubleshoot-dax-performance-use-dax-studio.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=2135\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\3-troubleshoot-dax-performance-use-dax-studio.plantuml\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\4-optimize-data-model-use-best-practice-analyzer.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1792\n",
      "output\\DP-600.Use tools to optimize Power BI performance\\4-optimize-data-model-use-best-practice-analyzer.plantuml\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\1-introduction.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=406\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\1-introduction.plantuml\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\2-understand-delta-lake.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=775\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\2-understand-delta-lake.plantuml\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\3-create-delta-tables.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=1270\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\3-create-delta-tables.plantuml\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\4-work-delta-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=717\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\4-work-delta-data.plantuml\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\5-use-delta-lake-streaming-data.md\n",
      "- Retrieving chat response (plantuml, maxtokens=13000)\n",
      "- Actual total usage token=982\n",
      "output\\DP-600.Work with Delta Lake tables in Microsoft Fabric\\5-use-delta-lake-streaming-data.plantuml\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "md_files = glob.glob('output/**/*.md', recursive=True)\n",
    "for md_file in md_files:\n",
    "    print(md_file)\n",
    "\n",
    "    with open(md_file, \"r\", encoding=\"utf8\") as md_file_handle:\n",
    "        markdown = md_file_handle.read()\n",
    "\n",
    "    outpufFile_plantuml = md_file.replace(\".md\", \".plantuml\")\n",
    "\n",
    "    plantuml = get_chat_response(\"plantuml\", markdown, outpufFile_plantuml, 13000, \"Generate the plantuml code\")\n",
    "    print(outpufFile_plantuml)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
