{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Generator\n",
    "\n",
    "This notebook support the creation of a podcast .mp3 audio file.\n",
    "\n",
    "When you listen to the generated podcast, you will notice an engaging conversation between the host and a guest, as they talk about the content of your choice. You determine what they talk about, as you can provide a list of web pages to take content from.\n",
    "\n",
    "The podcast generator uses the following technique to create the .mp3:\n",
    "\n",
    "1. Define a list of url's you want to use as the input for the podcast content. The generator will automatically fetch the content of these web pages and translate to markdown language\n",
    "2. Define who are the host and the guest\n",
    "3. For each web page, generate a podcast transcript (where the host and the guest have a conversation). This uses Azure OpenAI gpt3.5 deployed model.\n",
    "4. Transform the podcast transcript to SSML (Speech Synthesis Markup Language)\n",
    "5. Transform the SSML output to audio using Azure Cognitive Service Speech API\n",
    "6. Combine all the .mp3 files into one output\n",
    "\n",
    "Let's first get started by installing the pre-requisites (pip install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the name of the host and the guest. For a full list of voices, check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-text-to-speech?tabs=streaming\n",
    "\n",
    "| LocalName             | ShortName                       | Gender | WordsPerMinute |\n",
    "|-----------------------|---------------------------------|--------|----------------|\n",
    "| Ava                   | en-US-AvaNeural                 | Female |                |\n",
    "| Andrew                | en-US-AndrewNeural              | Male   |                |\n",
    "| Emma                  | en-US-EmmaNeural                | Female |                |\n",
    "| Brian                 | en-US-BrianNeural               | Male   |                |\n",
    "| Jenny *               | en-US-JennyNeural               | Female | 152            |\n",
    "| Guy *                 | en-US-GuyNeural                 | Male   | 215            |\n",
    "| Aria *                | en-US-AriaNeural                | Female | 150            |\n",
    "| Davis *               | en-US-DavisNeural               | Male   | 154            |\n",
    "| Jane *                | en-US-JaneNeural                | Female | 154            |\n",
    "| Jason *               | en-US-JasonNeural               | Male   | 156            |\n",
    "| Sara *                | en-US-SaraNeural                | Female | 157            |\n",
    "| Tony *                | en-US-TonyNeural                | Male   | 156            |\n",
    "| Nancy *               | en-US-NancyNeural               | Female | 149            |\n",
    "| Amber                 | en-US-AmberNeural               | Female | 152            |\n",
    "| Ana                   | en-US-AnaNeural                 | Female | 135            |\n",
    "| Ashley                | en-US-AshleyNeural              | Female | 149            |\n",
    "| Brandon               | en-US-BrandonNeural             | Male   | 156            |\n",
    "| Christopher           | en-US-ChristopherNeural         | Male   | 149            |\n",
    "| Cora                  | en-US-CoraNeural                | Female | 146            |\n",
    "| Elizabeth             | en-US-ElizabethNeural           | Female | 152            |\n",
    "| Eric                  | en-US-EricNeural                | Male   | 147            |\n",
    "| Jacob                 | en-US-JacobNeural               | Male   | 154            |\n",
    "| Jenny Multilingual    | en-US-JennyMultilingualNeural   | Female | 190            |\n",
    "| Jenny Multilingual V2 | en-US-JennyMultilingualV2Neural | Female | 190            |\n",
    "| Michelle              | en-US-MichelleNeural            | Female | 154            |\n",
    "| Monica                | en-US-MonicaNeural              | Female | 145            |\n",
    "| Roger                 | en-US-RogerNeural               | Male   |                |\n",
    "| Ryan Multilingual     | en-US-RyanMultilingualNeural    | Male   | 190            |\n",
    "| Steffan               | en-US-SteffanNeural             | Male   | 154            |\n",
    "\n",
    "** Have styles in preview (for example, assistant, newscast, angry, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"Brian\"\n",
    "guest = \"Emma\"\n",
    "podcast_title = \"DP600, Implementing Analytics Solutions Using Microsoft Fabric\"\n",
    "code = \"DP-600\"\n",
    "learn_module = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "import requests\n",
    "import markdownify\n",
    "import re\n",
    "import json\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from openai import AzureOpenAI\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve markdown text for a URL\n",
    "\n",
    "The following function will download the page content from the URL parameter. \n",
    "\n",
    "- It will then find the div with id `unit-inner-section`. \n",
    "- Next, it removes some metadata from the HTML. \n",
    "- Finally, the returning text will be transformed to markdown content as the return value for this function. Markdown is a bit easier to work with when using it as input for gpt model (as it will preserve headers, ...)\n",
    "- The function will also store the markdown content in the output folder (mainly for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markdown(url, savelocation):\n",
    "    print(\"- Retrieving markdown from \" + url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # might need to adapt this when working with other web pages (not Microsoft Learn)\n",
    "    div = soup.find(id=\"unit-inner-section\")\n",
    "\n",
    "    for ul in div.find_all(\"ul\", class_=\"metadata\"):\n",
    "        ul.decompose()\n",
    "    for d in div.find_all(\"div\", class_=\"xp-tag\"):\n",
    "        d.decompose()\n",
    "    for next in div.find_all(\"div\", class_=\"next-section\"):\n",
    "        next.decompose()\n",
    "    for header in div.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "        header.string = \"\\n# \" + header.get_text() + \"\\n\"\n",
    "    for code in div.find_all(\"code\"):\n",
    "        code.decompose()\n",
    "\n",
    "    markdown = markdownify.markdownify(str(div), heading_style=\"ATX\", bullets=\"-\")\n",
    "    markdown = re.sub('\\n{3,}', '\\n\\n', markdown)\n",
    "    markdown = markdown.replace(\"[Continue](/en-us/)\", \"\")\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(markdown)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Azure OpenAI chat response\n",
    "\n",
    "This function will call the Azure OpenAI GPT model. Follow these steps:\n",
    "\n",
    "1. Deploy an Azure OpenAI Service resource (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)\n",
    "2. Deploy a model \"gpt-35-turbo-16k\". If possible, you can also deploy \"gpt-4-32k\" if quota is available. The more tokens you have, the less issues you will experience when calling the chat service. (https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model)\n",
    "3. Retrieve the OPENAI_API_KEY and store it in the .env file\n",
    "\n",
    "The following code makes use op some predefined prompts. The idea is that every webpage (markdown) will be attached as content when asking the gpt model to generate a podcast transcript. Since we want the transcript opening and closing section to be different, we have multiple prompts.\n",
    "\n",
    "Notice that the characters of the host and guest are defined in another template.\n",
    "\n",
    "For troubleshooting purposes, the output of the chat completion is also stored as a file in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(action, content, savelocation, maxtokens=13000, userMessage=\"Generate the podcast\"):\n",
    "    print(f\"- Retrieving chat response ({action}, maxtokens={maxtokens})\")\n",
    "    client = AzureOpenAI(azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"), api_version=\"2023-07-01-preview\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    with open(\"prompts/prompt_characters.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt_characters = text_file.read()\n",
    "\n",
    "    with open(f\"prompts/prompt_{action}.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "        prompt = text_file.read()\n",
    "\n",
    "    prompt = prompt.replace(\"{characters}\", prompt_characters)\n",
    "    prompt = prompt.replace(\"{host}\", host)\n",
    "    prompt = prompt.replace(\"{guest}\", guest)\n",
    "    prompt = prompt.replace(\"{content}\", content)\n",
    "    prompt = prompt.replace(\"{podcast_title}\", podcast_title)\n",
    "\n",
    "    message_text = [\n",
    "        {\"role\":\"system\",\"content\":prompt},\n",
    "        {\"role\":\"user\",\"content\":userMessage}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-16k\",\n",
    "        messages = message_text,\n",
    "        temperature=0.1,\n",
    "        #max_tokens=13000,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "    print(f\"- Actual total usage token={completion.usage.total_tokens}\")\n",
    "\n",
    "    with open(savelocation, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MP3 audio\n",
    "\n",
    "The following function takes the SSML transcript and uses the Azure Speech Service to transform the text into speech.\n",
    "\n",
    "1. You will need to deploy an Azure Speech Service. Check out https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-text-to-speech for more information.\n",
    "2. Fetch the SPEECH_API_KEY and store in the .env file.\n",
    "\n",
    "As a result, an .mp3 file will be created in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(ssml, savelocation):\n",
    "    print(f\"- Creating audio {savelocation}\")\n",
    "    \n",
    "    service_region = \"eastus\"\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3)  \n",
    "\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=savelocation)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)  \n",
    "\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append multiple mp3 files\n",
    "\n",
    "Since we have multiple .mp3 files, we want to merge/append them together sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the combined podcast .mp3 file\n",
    "\n",
    "This code will first get a list of all the generated .mp3 files, and combine them with a couple of short audio tunes to indicate start, break and finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineAudio(templocation, savelocation):\n",
    "    input_files = fnmatch.filter(os.listdir(templocation), '*.mp3')\n",
    "    final_files = []\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        input_files[i] = os.path.join(templocation, input_files[i])\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        if i == 0:\n",
    "            final_files.append(\"media\\\\start.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "        elif i == len(input_files) - 1:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "            final_files.append(\"media/finish.mp3\")\n",
    "        elif i == 1:\n",
    "            final_files.append(input_files[i]) # skip the first break (as the introduction is only a few minutes long)\n",
    "        else:\n",
    "            final_files.append(\"media\\\\break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "\n",
    "    print(\"- Combining audio files \" + str(final_files))\n",
    "    \n",
    "    # Initialize an empty AudioSegment\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through input files and append them to the combined_audio\n",
    "    for input_file in final_files:\n",
    "        audio_segment = AudioSegment.from_file(input_file, format=\"mp3\")\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Export the combined audio to the output file\n",
    "    combined_audio.export(savelocation, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text): \n",
    "    nrOfWords = len(text.split())\n",
    "    return nrOfWords\n",
    "\n",
    "def calculate_approx_tokens(text):\n",
    "    nrOfTokens = round(calculate_number_words(text) * 3)\n",
    "    if nrOfTokens > 13000:\n",
    "        nrOfTokens = 13000\n",
    "    return nrOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "\n",
    "    modules = [module for module in lp[\"learning_modules\"] if module[\"learning_module\"] == learn_module or learn_module == \"all\"]\n",
    "    for module in modules:\n",
    "        outputFolder_module = f\"output/{code}.{module['learning_module']}\"\n",
    "        outputFile_module_mp3 = f\"output/{code}.{module['learning_module']}.mp3\"\n",
    "\n",
    "        if not os.path.exists(outputFolder_module):\n",
    "            os.mkdir(outputFolder_module)\n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            if index == 0:\n",
    "                action = \"start\"\n",
    "            elif index == len(module[\"learning_units\"]) - 1:\n",
    "                action = \"finish\"\n",
    "            else:\n",
    "                action = \"between\"\n",
    "            \n",
    "            outputFile_md = f\"{outputFolder_module}/{unit_name}.md\"\n",
    "            outpufFile_transcript = f\"{outputFolder_module}/{unit_name}.transcript.txt\"\n",
    "            outputFile_ssml = f\"{outputFolder_module}/{unit_name}.ssml.xml\"\n",
    "            outputFile_unit_mp3 = f\"{outputFolder_module}/{unit_name}.mp3\"\n",
    "            \n",
    "            markdown = get_markdown(url, outputFile_md)\n",
    "            transcript = get_chat_response(action, markdown, outpufFile_transcript, calculate_approx_tokens(markdown))\n",
    "            ssml = get_chat_response(\"ssml\", transcript, outputFile_ssml)\n",
    "            #audio = get_audio(ssml, outputFile_unit_mp3)\n",
    "\n",
    "            #break\n",
    "\n",
    "        #combineAudio(outputFolder_module , outputFile_module_mp3)\n",
    "\n",
    "        #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "\n",
    "for lp in learning_paths:\n",
    "\n",
    "    modules = [module for module in lp[\"learning_modules\"] if module[\"learning_module\"] == learn_module or learn_module == \"all\"]\n",
    "    for module in modules:\n",
    "        outputFolder_module = f\"output/{code}.{module['learning_module']}\"\n",
    "        outputFile_module_mp3 = f\"output/{code}.{module['learning_module']}.mp3\"\n",
    "\n",
    "        for index, url in enumerate(module[\"learning_units\"]):\n",
    "            unit_name = url.split(\"/\")[-1]\n",
    "\n",
    "            outputFile_ssml = f\"{outputFolder_module}/{unit_name}.ssml.xml\"\n",
    "            outputFile_unit_mp3 = f\"{outputFolder_module}/{unit_name}.mp3\"\n",
    "\n",
    "            with open(outputFile_ssml, \"r\", encoding=\"utf8\") as ssml_file:\n",
    "                ssml = ssml_file.read()\n",
    "            \n",
    "            audio = get_audio(ssml, outputFile_unit_mp3)\n",
    "\n",
    "            #break\n",
    "\n",
    "        combineAudio(outputFolder_module , outputFile_module_mp3)\n",
    "\n",
    "        #break\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "md_files = glob.glob('output/**/*.md', recursive=True)\n",
    "for md_file in md_files:\n",
    "    print(md_file)\n",
    "\n",
    "    with open(md_file, \"r\", encoding=\"utf8\") as md_file_handle:\n",
    "        markdown = md_file_handle.read()\n",
    "\n",
    "    outpufFile_plantuml = md_file.replace(\".md\", \".plantuml\")\n",
    "\n",
    "    plantuml = get_chat_response(\"plantuml\", markdown, outpufFile_plantuml, 13000, \"Generate the plantuml code\")\n",
    "    print(outpufFile_plantuml)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
