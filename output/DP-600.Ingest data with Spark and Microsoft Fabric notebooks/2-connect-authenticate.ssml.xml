<speak xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xmlns:emo="http://www.w3.org/2009/10/emotionml" version="1.0" xml:lang="en-US">
<voice name="en-US-BrianNeural">
So Emma, now that we know how to connect to external sources using Fabric notebooks, how do we load the data into a file or table?
</voice>
<voice name="en-US-EmmaNeural">
Great question, Brian. Loading the data into a file or table is the next step after connecting to the external source. In Fabric notebooks, we can use the `write` method to save the data to a file or table. Let me show you an example.
</voice>
<voice name="en-US-EmmaNeural">
Suppose we have a DataFrame called `df` that contains the data we want to save. We can use the following code to save it as a parquet file:
</voice>
<voice name="en-US-BrianNeural">
df.write.format("parquet").save("/path/to/save/location")
</voice>
<voice name="en-US-EmmaNeural">
And if we want to save it as a table in Azure Synapse Analytics, we can use the following code:
</voice>
<voice name="en-US-BrianNeural">
df.write.format("synapsesql").option("url", "jdbc:sqlserver://<server>:<port>;database=<database>").option("dbtable", "<table_name>").option("user", "<username>").option("password", "<password>").save()
</voice>
<voice name="en-US-EmmaNeural">
These are just a couple of examples, but you can also save the data in other formats like CSV, JSON, or Avro. The `write` method provides flexibility in choosing the format that best suits your needs.
</voice>
<voice name="en-US-BrianNeural">
That's really helpful, Emma. So, once we've loaded the data into a file or table, can we perform any transformations on it?
</voice>
<voice name="en-US-EmmaNeural">
Absolutely, Brian. Fabric notebooks provide a wide range of transformation capabilities. You can use Spark SQL, DataFrame operations, or even custom functions to transform the data. Let me give you an example.
</voice>
<voice name="en-US-EmmaNeural">
Suppose we have a DataFrame called `df` that contains customer data. We can use the following code to filter out customers who have made more than 10 purchases:
</voice>
<voice name="en-US-BrianNeural">
filtered_df = df.filter(df.purchases > 10)
</voice>
<voice name="en-US-EmmaNeural">
This code applies a filter condition to the DataFrame and creates a new DataFrame called `filtered_df` that only contains the customers who meet the criteria.
</voice>
<voice name="en-US-BrianNeural">
That's really powerful, Emma. Being able to perform transformations directly in the notebook makes it so much easier. Can we also join multiple datasets together?
</voice>
<voice name="en-US-EmmaNeural">
Absolutely, Brian. Joining multiple datasets is a common operation in data analytics. In Fabric notebooks, you can use the `join` method to perform joins between DataFrames. Let me show you an example.
</voice>
<voice name="en-US-EmmaNeural">
Suppose we have two DataFrames, `df1` and `df2`, that contain customer data and order data respectively. We can use the following code to join them based on a common column:
</voice>
<voice name="en-US-BrianNeural">
joined_df = df1.join(df2, df1.customer_id == df2.customer_id, "inner")
</voice>
<voice name="en-US-EmmaNeural">
This code performs an inner join between `df1` and `df2` based on the `customer_id` column and creates a new DataFrame called `joined_df` that contains the combined data.
</voice>
<voice name="en-US-BrianNeural">
That's fantastic, Emma. Being able to join datasets directly in the notebook saves a lot of time and effort. Thank you for explaining all these concepts so clearly.
</voice>
<voice name="en-US-EmmaNeural">
You're welcome, Brian. I'm glad I could help. Fabric notebooks provide a powerful and efficient way to implement analytics solutions using Microsoft Fabric. If you have any more questions, feel free to ask.
</voice>
<voice name="en-US-BrianNeural">
That's an excellent insight, Emma. I'll definitely keep that in mind. Thank you for sharing your expertise with us today.
</voice>
<voice name="en-US-EmmaNeural">
My pleasure, Brian. It was great talking to you. Have a great day!
</voice>
</speak>