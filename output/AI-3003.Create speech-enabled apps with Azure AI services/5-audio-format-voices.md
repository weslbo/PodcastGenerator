
# 
# Configure audio format and voices

When synthesizing speech, you can use a **SpeechConfig** object to customize the audio that is returned by the Azure AI Speech service.

## 
# Audio format

The Azure AI Speech service supports multiple output formats for the audio stream that is generated by speech synthesis. Depending on your specific needs, you can choose a format based on the required:

- Audio file type
- Sample-rate
- Bit-depth

The supported formats are indicated in the SDK using the **SpeechSynthesisOutputFormat** enumeration. For example, .

To specify the required output format, use the **SetSpeechSynthesisOutputFormat** method of the **SpeechConfig** object:

For a full list of supported formats and their enumeration values, see the [Azure AI Speech SDK documentation](/en-us/dotnet/api/microsoft.cognitiveservices.speech.speechsynthesisoutputformat).

## 
# Voices

The Azure AI Speech service provides multiple voices that you can use to personalize your speech-enabled applications. There are two kinds of voice that you can use:

- *Standard voices* - synthetic voices created from audio samples.
- *Neural voices* - more natural sounding voices created using deep neural networks.

Voices are identified by names that indicate a locale and a person's name - for example .

To specify a voice for speech synthesis in the **SpeechConfig**, set its **SpeechSynthesisVoiceName** property to the voice you want to use:

For information about voices, see the [Azure AI Speech SDK documentation](/en-us/azure/ai-services/speech-service/language-support?tabs=tts).



